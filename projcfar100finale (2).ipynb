{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile util.py\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "def exportModel(history, polarity, amsgrad, model, bias):\n",
        "  \"\"\"\n",
        "  this function allows us to save the model in its final state\n",
        "  for later experimentation, use, and reproducability storage\n",
        "\n",
        "  NOTE: this function is designed for google colab\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  fileName=\"cifar100_\"+str(polarity)+\"_\"+str(amsgrad)+\"_B\"+str(bias)+\".keras\"\n",
        "  print(fileName)\n",
        "  model.save(fileName)\n",
        "  #files.download(fileName)\n",
        "\n",
        "\n",
        "def getData(reproSeed=1):\n",
        "  \"\"\"\n",
        "  this function not only grabs the data from the source\n",
        "  but also does a true 3 way split\n",
        "  as a 2 way split is only performed by default\n",
        "  which does not provide validation data\n",
        "\n",
        "  this function also prepares the data in a way\n",
        "  that works well with our model setup\n",
        "  \"\"\"\n",
        "\n",
        "  # first split, from obtaining the data\n",
        "  (trainValImgs, trainValLabels),(testImgs, testLabels)= datasets.cifar100.load_data( )\n",
        "\n",
        "  # normalize the values because 255 format\n",
        "  # makes things difficult\n",
        "  trainValImgs = trainValImgs/255\n",
        "  testImgs = testImgs/255\n",
        "\n",
        "  #flatten to ensure compatable with later functions\n",
        "  trainValLabels = trainValLabels.ravel()\n",
        "  testLabels = testLabels.ravel()\n",
        "\n",
        "\n",
        "  # second split is needed to run testing\n",
        "  trainImgs, valImgs, trainLabels, valLabels = train_test_split(trainValImgs,\n",
        "                                                              trainValLabels,\n",
        "                                                              test_size=0.25,\n",
        "                                                              random_state=reproSeed)\n",
        "\n",
        "  return trainImgs, valImgs, trainLabels, valLabels, testImgs, testLabels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUFKHQIVvcP1",
        "outputId": "5fed629e-3aa5-43a2-9acf-b22b580e3dce"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting util.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqvD5CYRt_jY",
        "outputId": "01f865b9-a184-45f0-8f1b-d060c0194cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "def modelMaker(amsgrad= False, polarity = \"up\", bias=False):\n",
        "  \"\"\"\n",
        "  this function creates and compiles a model\n",
        "\n",
        "  there are two settings for the architecture:\n",
        "    'up'   : the convolutional layers build up in filter count\n",
        "    'down' : the convolutional layers build down on filter count\n",
        "    (all kernels are the same size)\n",
        "\n",
        "  there are two settings for hyperparamters\n",
        "    'True' : ams grad is on\n",
        "    'False': ams grad is off\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  match polarity:\n",
        "    case \"up\":\n",
        "      model = models.Sequential([\n",
        "        layers.Input(shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        #layers.Conv2D(32, 3, strides=2, padding='same', use_bias=False),\n",
        "\n",
        "        layers.Conv2D(32, 3, padding='same', use_bias=bias), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(64, 3, padding='same', use_bias=bias), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(128, 3, padding='same', use_bias=bias), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "        layers.Flatten(),\n",
        "\n",
        "\n",
        "        layers.Dense(256, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(128, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(100, activation=\"softmax\")\n",
        "      ])\n",
        "      adamm=Adam(amsgrad=amsgrad)\n",
        "      model.compile(optimizer=adamm,\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "      return model\n",
        "\n",
        "\n",
        "    case \"down\":\n",
        "      model = models.Sequential([\n",
        "        layers.Input(shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        #layers.Conv2D(32, 3, strides=2, padding='same', use_bias=False),\n",
        "\n",
        "        layers.Conv2D(128, 3, padding='same', use_bias=bias), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(64, 3, padding='same', use_bias=bias), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(32, 3, padding='same', use_bias=bias), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "        layers.Flatten(),\n",
        "\n",
        "\n",
        "        layers.Dense(256, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(128, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(100, activation=\"softmax\")\n",
        "      ])\n",
        "      adamm=Adam(amsgrad=amsgrad)\n",
        "      model.compile(optimizer=adamm,\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "      return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "\n",
        "from util import *\n",
        "from model import *\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mainrun(polarity, amsgrad, bias):\n",
        "  \"\"\"\n",
        "  this function is the main run for setting up\n",
        "  fitting, testing, and exporting our model\n",
        "\n",
        "  there are some manipulatable settings\n",
        "  but nothing that should be changed between tests\n",
        "  \"\"\"\n",
        "  # seed for reproducability\n",
        "  reproSeed=1\n",
        "  # max epochs\n",
        "  epoccs=100#20#00\n",
        "  # early stopping, does not always activate\n",
        "  # due to other regularizers at play\n",
        "  callback = callbacks.EarlyStopping(monitor='loss',\n",
        "                                                patience=5,\n",
        "                                                restore_best_weights=True)\n",
        "\n",
        "  # get cifar100 fine data with full 3 way split\n",
        "  trainImgs, valImgs, trainLabels, valLabels, testImgs, testLabels = getData(reproSeed=reproSeed)\n",
        "\n",
        "  # generate the model with architecture based on up or down\n",
        "  # and amsgrad on or off\n",
        "  model = modelMaker(amsgrad=amsgrad , polarity=polarity, bias=bias)\n",
        "\n",
        "  # show relavant information about the model\n",
        "  print(\"polarity:\", polarity,\"   amsgrad:\",  amsgrad)\n",
        "  model.summary()\n",
        "\n",
        "  # fit the model\n",
        "  history = model.fit(\n",
        "    trainImgs, trainLabels, epochs=epoccs, validation_data=(valImgs, valLabels),\n",
        "    callbacks=[callback], batch_size=50\n",
        "  )\n",
        "\n",
        "  # download the model so you can use it later\n",
        "  exportModel(history=history, polarity=polarity, amsgrad=amsgrad, model=model, bias=bias)\n",
        "\n",
        "  # placeholder until we get resampled CI testacc\n",
        "  testLoss, testAcc = model.evaluate(testImgs, testLabels)\n",
        "  print(f\"Test Accuracy: {testAcc*100:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  \"\"\"\n",
        "  each of these function calls is a new test\n",
        "  we need four total\n",
        "  (two architectures two hyperparameters)\n",
        "  more can be added, and individual ones can\n",
        "  be commed out\n",
        "  since these models take a long time to train\n",
        "\n",
        "  This setup helps maintain that we change\n",
        "  what we are interested in for the experiment\n",
        "  and hold all else constant\n",
        "  \"\"\"\n",
        "\n",
        "  #mainrun(polarity=\"up\", amsgrad=False,bias=False)\n",
        "  #mainrun(polarity=\"up\", amsgrad=True, bias=False)\n",
        "  #mainrun(polarity=\"down\", amsgrad=False,bias=False)\n",
        "  #mainrun(polarity=\"down\", amsgrad=True,bias=False)\n",
        "\n",
        "  mainrun(polarity=\"up\", amsgrad=False,bias=True)\n",
        "  mainrun(polarity=\"up\", amsgrad=True, bias=True)\n",
        "  mainrun(polarity=\"down\", amsgrad=False,bias=True)\n",
        "  mainrun(polarity=\"down\", amsgrad=True,bias=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UfILMXtvDsc",
        "outputId": "b9834cee-7048-4566-fc54-26def19c692d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPcJDqOq2ILS",
        "outputId": "d4caa0c9-322e-42ba-ec3b-41fa5b22e2b7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-08 19:15:47.771800: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:95] Opening library: /usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2\n",
            "2024-07-08 19:15:47.772005: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:119] Libtpu path is: libtpu.so\n",
            "2024-07-08 19:15:47.819630: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-08 19:15:58.146924: I external/local_xla/xla/service/service.cc:168] XLA service 0x5cb4f8971600 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\n",
            "2024-07-08 19:15:58.146975: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): TPU, 2a886c8\n",
            "2024-07-08 19:15:58.146989: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): TPU, 2a886c8\n",
            "2024-07-08 19:15:58.146999: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (2): TPU, 2a886c8\n",
            "2024-07-08 19:15:58.147006: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (3): TPU, 2a886c8\n",
            "2024-07-08 19:15:58.147015: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (4): TPU, 2a886c8\n",
            "2024-07-08 19:15:58.147025: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (5): TPU, 2a886c8\n",
            "2024-07-08 19:15:58.147033: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (6): TPU, 2a886c8\n",
            "2024-07-08 19:15:58.147043: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (7): TPU, 2a886c8\n",
            "2024-07-08 19:15:58.147202: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.147285: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.147342: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.147398: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.147449: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.147646: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.147735: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.147794: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.147862: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.147949: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.148152: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.148258: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.148347: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.148408: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.148492: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.148636: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.148715: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.148794: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.148871: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.148938: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.149103: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.149176: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.149248: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.149324: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.149430: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.149613: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.149682: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.149770: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.149840: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.149927: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.150101: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.150177: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.150258: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.150345: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.150432: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.150662: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.150723: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.150810: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.150882: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 19:15:58.150982: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "polarity: up    amsgrad: False\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (Batch  (None, 32, 32, 3)         12        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664496 (2.53 MB)\n",
            "Trainable params: 664042 (2.53 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 28s 35ms/step - loss: 4.8600 - accuracy: 0.1393 - val_loss: 3.6314 - val_accuracy: 0.2217\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 3.4614 - accuracy: 0.2502 - val_loss: 3.2664 - val_accuracy: 0.2950\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 3.2090 - accuracy: 0.3062 - val_loss: 3.0942 - val_accuracy: 0.3290\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 3.0601 - accuracy: 0.3409 - val_loss: 3.0133 - val_accuracy: 0.3502\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.9807 - accuracy: 0.3589 - val_loss: 2.9894 - val_accuracy: 0.3630\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.9063 - accuracy: 0.3793 - val_loss: 2.8982 - val_accuracy: 0.3858\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.8463 - accuracy: 0.3944 - val_loss: 2.8601 - val_accuracy: 0.4010\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.8089 - accuracy: 0.4047 - val_loss: 2.8514 - val_accuracy: 0.3979\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.7672 - accuracy: 0.4217 - val_loss: 2.8443 - val_accuracy: 0.3993\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.7294 - accuracy: 0.4263 - val_loss: 2.7986 - val_accuracy: 0.4151\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.6908 - accuracy: 0.4314 - val_loss: 2.7846 - val_accuracy: 0.4140\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.6723 - accuracy: 0.4367 - val_loss: 2.7758 - val_accuracy: 0.4182\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.6569 - accuracy: 0.4441 - val_loss: 2.8845 - val_accuracy: 0.4097\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.6307 - accuracy: 0.4479 - val_loss: 2.7220 - val_accuracy: 0.4332\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.6162 - accuracy: 0.4539 - val_loss: 2.7830 - val_accuracy: 0.4308\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.5785 - accuracy: 0.4588 - val_loss: 2.7325 - val_accuracy: 0.4270\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.5696 - accuracy: 0.4612 - val_loss: 2.6908 - val_accuracy: 0.4481\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.5659 - accuracy: 0.4662 - val_loss: 2.6919 - val_accuracy: 0.4422\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.5502 - accuracy: 0.4662 - val_loss: 2.6337 - val_accuracy: 0.4525\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.5374 - accuracy: 0.4687 - val_loss: 2.7032 - val_accuracy: 0.4470\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.5409 - accuracy: 0.4696 - val_loss: 2.6294 - val_accuracy: 0.4585\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.5217 - accuracy: 0.4736 - val_loss: 2.7346 - val_accuracy: 0.4364\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.5005 - accuracy: 0.4752 - val_loss: 2.6539 - val_accuracy: 0.4566\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.4984 - accuracy: 0.4823 - val_loss: 2.7232 - val_accuracy: 0.4565\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.5067 - accuracy: 0.4809 - val_loss: 2.6710 - val_accuracy: 0.4514\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.4823 - accuracy: 0.4815 - val_loss: 2.6408 - val_accuracy: 0.4561\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.4571 - accuracy: 0.4906 - val_loss: 2.6602 - val_accuracy: 0.4533\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.4569 - accuracy: 0.4873 - val_loss: 2.6384 - val_accuracy: 0.4625\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.4445 - accuracy: 0.4911 - val_loss: 2.6892 - val_accuracy: 0.4450\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.4458 - accuracy: 0.4901 - val_loss: 2.6488 - val_accuracy: 0.4599\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.4246 - accuracy: 0.4920 - val_loss: 2.6961 - val_accuracy: 0.4530\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.4077 - accuracy: 0.4979 - val_loss: 2.6081 - val_accuracy: 0.4598\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.4076 - accuracy: 0.4958 - val_loss: 2.5910 - val_accuracy: 0.4586\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3866 - accuracy: 0.4960 - val_loss: 2.5647 - val_accuracy: 0.4755\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.3627 - accuracy: 0.5010 - val_loss: 2.6825 - val_accuracy: 0.4469\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3679 - accuracy: 0.4998 - val_loss: 2.5243 - val_accuracy: 0.4730\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3311 - accuracy: 0.5010 - val_loss: 2.6112 - val_accuracy: 0.4458\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3334 - accuracy: 0.5030 - val_loss: 2.5052 - val_accuracy: 0.4706\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3128 - accuracy: 0.5063 - val_loss: 2.5281 - val_accuracy: 0.4696\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3028 - accuracy: 0.5036 - val_loss: 2.5455 - val_accuracy: 0.4684\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 2.3066 - accuracy: 0.5049 - val_loss: 2.5402 - val_accuracy: 0.4666\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2820 - accuracy: 0.5103 - val_loss: 2.5336 - val_accuracy: 0.4630\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2807 - accuracy: 0.5074 - val_loss: 2.5200 - val_accuracy: 0.4654\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2604 - accuracy: 0.5146 - val_loss: 2.4551 - val_accuracy: 0.4791\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2694 - accuracy: 0.5115 - val_loss: 2.5010 - val_accuracy: 0.4695\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2620 - accuracy: 0.5133 - val_loss: 2.4580 - val_accuracy: 0.4751\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2549 - accuracy: 0.5151 - val_loss: 2.4876 - val_accuracy: 0.4689\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2464 - accuracy: 0.5145 - val_loss: 2.5261 - val_accuracy: 0.4650\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2420 - accuracy: 0.5155 - val_loss: 2.4378 - val_accuracy: 0.4825\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2338 - accuracy: 0.5156 - val_loss: 2.4295 - val_accuracy: 0.4830\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2277 - accuracy: 0.5201 - val_loss: 2.4614 - val_accuracy: 0.4836\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2299 - accuracy: 0.5195 - val_loss: 2.4664 - val_accuracy: 0.4760\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2223 - accuracy: 0.5239 - val_loss: 2.4584 - val_accuracy: 0.4830\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2254 - accuracy: 0.5219 - val_loss: 2.4698 - val_accuracy: 0.4848\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.2152 - accuracy: 0.5228 - val_loss: 2.5072 - val_accuracy: 0.4670\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.2170 - accuracy: 0.5229 - val_loss: 2.4173 - val_accuracy: 0.4870\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2015 - accuracy: 0.5251 - val_loss: 2.4230 - val_accuracy: 0.4854\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2068 - accuracy: 0.5265 - val_loss: 2.4571 - val_accuracy: 0.4823\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2007 - accuracy: 0.5275 - val_loss: 2.4291 - val_accuracy: 0.4908\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1936 - accuracy: 0.5287 - val_loss: 2.4149 - val_accuracy: 0.4868\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.1977 - accuracy: 0.5260 - val_loss: 2.4812 - val_accuracy: 0.4787\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1953 - accuracy: 0.5268 - val_loss: 2.4912 - val_accuracy: 0.4709\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1941 - accuracy: 0.5271 - val_loss: 2.4258 - val_accuracy: 0.4865\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1957 - accuracy: 0.5257 - val_loss: 2.4161 - val_accuracy: 0.4874\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.1814 - accuracy: 0.5294 - val_loss: 2.5007 - val_accuracy: 0.4724\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.1860 - accuracy: 0.5274 - val_loss: 2.4644 - val_accuracy: 0.4855\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1805 - accuracy: 0.5293 - val_loss: 2.4294 - val_accuracy: 0.4833\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1755 - accuracy: 0.5361 - val_loss: 2.4511 - val_accuracy: 0.4824\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1759 - accuracy: 0.5312 - val_loss: 2.5184 - val_accuracy: 0.4741\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.1753 - accuracy: 0.5314 - val_loss: 2.4520 - val_accuracy: 0.4857\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1650 - accuracy: 0.5350 - val_loss: 2.4679 - val_accuracy: 0.4810\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.1599 - accuracy: 0.5385 - val_loss: 2.4245 - val_accuracy: 0.4850\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1621 - accuracy: 0.5344 - val_loss: 2.4615 - val_accuracy: 0.4780\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1619 - accuracy: 0.5341 - val_loss: 2.4111 - val_accuracy: 0.4942\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.1597 - accuracy: 0.5348 - val_loss: 2.4704 - val_accuracy: 0.4766\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1556 - accuracy: 0.5370 - val_loss: 2.4847 - val_accuracy: 0.4830\n",
            "Epoch 77/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.1587 - accuracy: 0.5345 - val_loss: 2.4577 - val_accuracy: 0.4833\n",
            "Epoch 78/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1533 - accuracy: 0.5379 - val_loss: 2.4401 - val_accuracy: 0.4823\n",
            "Epoch 79/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.1490 - accuracy: 0.5409 - val_loss: 2.4547 - val_accuracy: 0.4874\n",
            "Epoch 80/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1487 - accuracy: 0.5398 - val_loss: 2.4340 - val_accuracy: 0.4922\n",
            "Epoch 81/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1496 - accuracy: 0.5395 - val_loss: 2.4426 - val_accuracy: 0.4890\n",
            "Epoch 82/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1525 - accuracy: 0.5381 - val_loss: 2.4274 - val_accuracy: 0.4892\n",
            "Epoch 83/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1508 - accuracy: 0.5378 - val_loss: 2.4186 - val_accuracy: 0.4907\n",
            "Epoch 84/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1426 - accuracy: 0.5402 - val_loss: 2.4642 - val_accuracy: 0.4823\n",
            "Epoch 85/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.1472 - accuracy: 0.5374 - val_loss: 2.4249 - val_accuracy: 0.4941\n",
            "Epoch 86/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.1357 - accuracy: 0.5443 - val_loss: 2.4750 - val_accuracy: 0.4836\n",
            "Epoch 87/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1442 - accuracy: 0.5393 - val_loss: 2.4404 - val_accuracy: 0.4904\n",
            "Epoch 88/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1328 - accuracy: 0.5411 - val_loss: 2.4925 - val_accuracy: 0.4783\n",
            "Epoch 89/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.1344 - accuracy: 0.5453 - val_loss: 2.4282 - val_accuracy: 0.4988\n",
            "Epoch 90/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1285 - accuracy: 0.5436 - val_loss: 2.4217 - val_accuracy: 0.4926\n",
            "Epoch 91/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.1432 - accuracy: 0.5398 - val_loss: 2.3981 - val_accuracy: 0.4939\n",
            "Epoch 92/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.1240 - accuracy: 0.5463 - val_loss: 2.4351 - val_accuracy: 0.4920\n",
            "Epoch 93/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1361 - accuracy: 0.5406 - val_loss: 2.4345 - val_accuracy: 0.4904\n",
            "Epoch 94/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.1309 - accuracy: 0.5450 - val_loss: 2.4656 - val_accuracy: 0.4850\n",
            "Epoch 95/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.1230 - accuracy: 0.5457 - val_loss: 2.4154 - val_accuracy: 0.4937\n",
            "Epoch 96/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1199 - accuracy: 0.5459 - val_loss: 2.4362 - val_accuracy: 0.4906\n",
            "Epoch 97/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.1308 - accuracy: 0.5435 - val_loss: 2.4475 - val_accuracy: 0.4921\n",
            "Epoch 98/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.1271 - accuracy: 0.5419 - val_loss: 2.4450 - val_accuracy: 0.4923\n",
            "Epoch 99/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.1232 - accuracy: 0.5470 - val_loss: 2.3946 - val_accuracy: 0.5010\n",
            "Epoch 100/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1108 - accuracy: 0.5500 - val_loss: 2.4703 - val_accuracy: 0.4832\n",
            "cifar100_up_False_BTrue.keras\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 2.4414 - accuracy: 0.4915\n",
            "Test Accuracy: 49.15%\n",
            "polarity: up    amsgrad: True\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_4 (Bat  (None, 32, 32, 3)         12        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664496 (2.53 MB)\n",
            "Trainable params: 664042 (2.53 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 29s 36ms/step - loss: 4.8434 - accuracy: 0.1414 - val_loss: 3.6839 - val_accuracy: 0.2066\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 3.4598 - accuracy: 0.2466 - val_loss: 3.2458 - val_accuracy: 0.2857\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 3.2062 - accuracy: 0.3036 - val_loss: 3.1644 - val_accuracy: 0.3091\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 3.0560 - accuracy: 0.3358 - val_loss: 3.1222 - val_accuracy: 0.3272\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.9592 - accuracy: 0.3593 - val_loss: 2.9784 - val_accuracy: 0.3591\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.8823 - accuracy: 0.3789 - val_loss: 2.9425 - val_accuracy: 0.3722\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.8202 - accuracy: 0.3925 - val_loss: 2.8269 - val_accuracy: 0.3866\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.7724 - accuracy: 0.4026 - val_loss: 2.8933 - val_accuracy: 0.3784\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.7273 - accuracy: 0.4139 - val_loss: 2.8146 - val_accuracy: 0.3934\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.7049 - accuracy: 0.4189 - val_loss: 2.8337 - val_accuracy: 0.4022\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.6580 - accuracy: 0.4314 - val_loss: 2.7651 - val_accuracy: 0.4132\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.6283 - accuracy: 0.4406 - val_loss: 2.7007 - val_accuracy: 0.4240\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 27s 35ms/step - loss: 2.6096 - accuracy: 0.4442 - val_loss: 2.7457 - val_accuracy: 0.4223\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.5884 - accuracy: 0.4473 - val_loss: 2.6916 - val_accuracy: 0.4308\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.5592 - accuracy: 0.4537 - val_loss: 2.6992 - val_accuracy: 0.4229\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.5516 - accuracy: 0.4570 - val_loss: 2.6447 - val_accuracy: 0.4476\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.5303 - accuracy: 0.4616 - val_loss: 2.6460 - val_accuracy: 0.4454\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.5089 - accuracy: 0.4669 - val_loss: 2.6053 - val_accuracy: 0.4486\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.4938 - accuracy: 0.4685 - val_loss: 2.6482 - val_accuracy: 0.4439\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.4936 - accuracy: 0.4729 - val_loss: 2.6940 - val_accuracy: 0.4402\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.4820 - accuracy: 0.4754 - val_loss: 2.6202 - val_accuracy: 0.4542\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.4735 - accuracy: 0.4730 - val_loss: 2.6503 - val_accuracy: 0.4471\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.4545 - accuracy: 0.4783 - val_loss: 2.6471 - val_accuracy: 0.4465\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.4455 - accuracy: 0.4859 - val_loss: 2.5705 - val_accuracy: 0.4620\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.4272 - accuracy: 0.4854 - val_loss: 2.6124 - val_accuracy: 0.4559\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.4253 - accuracy: 0.4843 - val_loss: 2.6277 - val_accuracy: 0.4496\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.4118 - accuracy: 0.4877 - val_loss: 2.5962 - val_accuracy: 0.4562\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3912 - accuracy: 0.4928 - val_loss: 2.5539 - val_accuracy: 0.4652\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3830 - accuracy: 0.4947 - val_loss: 2.5818 - val_accuracy: 0.4645\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3792 - accuracy: 0.4971 - val_loss: 2.5428 - val_accuracy: 0.4682\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3717 - accuracy: 0.4947 - val_loss: 2.5664 - val_accuracy: 0.4653\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3746 - accuracy: 0.4992 - val_loss: 2.6021 - val_accuracy: 0.4596\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3704 - accuracy: 0.4983 - val_loss: 2.5788 - val_accuracy: 0.4619\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3540 - accuracy: 0.5010 - val_loss: 2.5536 - val_accuracy: 0.4641\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3468 - accuracy: 0.5041 - val_loss: 2.6207 - val_accuracy: 0.4575\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3440 - accuracy: 0.5052 - val_loss: 2.6046 - val_accuracy: 0.4646\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3365 - accuracy: 0.5050 - val_loss: 2.6551 - val_accuracy: 0.4472\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3367 - accuracy: 0.5088 - val_loss: 2.5575 - val_accuracy: 0.4670\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3244 - accuracy: 0.5097 - val_loss: 2.6075 - val_accuracy: 0.4590\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3319 - accuracy: 0.5091 - val_loss: 2.6000 - val_accuracy: 0.4668\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3097 - accuracy: 0.5111 - val_loss: 2.5467 - val_accuracy: 0.4729\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3204 - accuracy: 0.5091 - val_loss: 2.4788 - val_accuracy: 0.4844\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3061 - accuracy: 0.5164 - val_loss: 2.5852 - val_accuracy: 0.4647\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2951 - accuracy: 0.5151 - val_loss: 2.5301 - val_accuracy: 0.4833\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3079 - accuracy: 0.5155 - val_loss: 2.5632 - val_accuracy: 0.4771\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3025 - accuracy: 0.5165 - val_loss: 2.5802 - val_accuracy: 0.4658\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2950 - accuracy: 0.5157 - val_loss: 2.5410 - val_accuracy: 0.4762\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2795 - accuracy: 0.5163 - val_loss: 2.5437 - val_accuracy: 0.4743\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2759 - accuracy: 0.5205 - val_loss: 2.5617 - val_accuracy: 0.4700\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2759 - accuracy: 0.5204 - val_loss: 2.5398 - val_accuracy: 0.4750\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2788 - accuracy: 0.5202 - val_loss: 2.6290 - val_accuracy: 0.4620\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2619 - accuracy: 0.5216 - val_loss: 2.5146 - val_accuracy: 0.4777\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2668 - accuracy: 0.5217 - val_loss: 2.5056 - val_accuracy: 0.4815\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2589 - accuracy: 0.5222 - val_loss: 2.5347 - val_accuracy: 0.4770\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2571 - accuracy: 0.5264 - val_loss: 2.5391 - val_accuracy: 0.4811\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2472 - accuracy: 0.5292 - val_loss: 2.5293 - val_accuracy: 0.4771\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2391 - accuracy: 0.5290 - val_loss: 2.5385 - val_accuracy: 0.4792\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2593 - accuracy: 0.5253 - val_loss: 2.5680 - val_accuracy: 0.4775\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2569 - accuracy: 0.5268 - val_loss: 2.5020 - val_accuracy: 0.4814\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2524 - accuracy: 0.5290 - val_loss: 2.5243 - val_accuracy: 0.4827\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2579 - accuracy: 0.5281 - val_loss: 2.5034 - val_accuracy: 0.4823\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2285 - accuracy: 0.5297 - val_loss: 2.4980 - val_accuracy: 0.4826\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2365 - accuracy: 0.5290 - val_loss: 2.5736 - val_accuracy: 0.4720\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2350 - accuracy: 0.5316 - val_loss: 2.5346 - val_accuracy: 0.4756\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2268 - accuracy: 0.5306 - val_loss: 2.5305 - val_accuracy: 0.4770\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2234 - accuracy: 0.5355 - val_loss: 2.5144 - val_accuracy: 0.4835\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2252 - accuracy: 0.5365 - val_loss: 2.5395 - val_accuracy: 0.4798\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2119 - accuracy: 0.5370 - val_loss: 2.4942 - val_accuracy: 0.4864\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2158 - accuracy: 0.5365 - val_loss: 2.5384 - val_accuracy: 0.4827\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2146 - accuracy: 0.5347 - val_loss: 2.4954 - val_accuracy: 0.4897\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2061 - accuracy: 0.5378 - val_loss: 2.5620 - val_accuracy: 0.4822\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 27s 35ms/step - loss: 2.2111 - accuracy: 0.5381 - val_loss: 2.5319 - val_accuracy: 0.4821\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2159 - accuracy: 0.5387 - val_loss: 2.5396 - val_accuracy: 0.4822\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2097 - accuracy: 0.5412 - val_loss: 2.5015 - val_accuracy: 0.4902\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2086 - accuracy: 0.5392 - val_loss: 2.5124 - val_accuracy: 0.4856\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2163 - accuracy: 0.5385 - val_loss: 2.4598 - val_accuracy: 0.4942\n",
            "cifar100_up_True_BTrue.keras\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 2.5079 - accuracy: 0.4890\n",
            "Test Accuracy: 48.90%\n",
            "polarity: down    amsgrad: False\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_8 (Bat  (None, 32, 32, 3)         12        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 128)       3584      \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 32, 32, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 16, 16, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 8, 8, 32)          18464     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 8, 8, 32)          128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 4, 4, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 4, 4, 32)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273872 (1.04 MB)\n",
            "Trainable params: 273418 (1.04 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 45s 58ms/step - loss: 4.8022 - accuracy: 0.1293 - val_loss: 3.6608 - val_accuracy: 0.1826\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 3.4835 - accuracy: 0.2181 - val_loss: 3.2494 - val_accuracy: 0.2680\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 3.2215 - accuracy: 0.2700 - val_loss: 3.0778 - val_accuracy: 0.2989\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 3.0573 - accuracy: 0.3065 - val_loss: 3.0564 - val_accuracy: 0.3052\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 2.9525 - accuracy: 0.3281 - val_loss: 2.8611 - val_accuracy: 0.3483\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.8617 - accuracy: 0.3476 - val_loss: 2.8021 - val_accuracy: 0.3644\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.7955 - accuracy: 0.3611 - val_loss: 2.7638 - val_accuracy: 0.3691\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 2.7425 - accuracy: 0.3771 - val_loss: 2.7032 - val_accuracy: 0.3820\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.7058 - accuracy: 0.3806 - val_loss: 2.7387 - val_accuracy: 0.3775\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.6687 - accuracy: 0.3875 - val_loss: 2.6283 - val_accuracy: 0.3946\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.6324 - accuracy: 0.3993 - val_loss: 2.6380 - val_accuracy: 0.3970\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 2.6043 - accuracy: 0.4051 - val_loss: 2.6009 - val_accuracy: 0.4087\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.5701 - accuracy: 0.4122 - val_loss: 2.5737 - val_accuracy: 0.4101\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 2.5532 - accuracy: 0.4135 - val_loss: 2.5381 - val_accuracy: 0.4209\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.5344 - accuracy: 0.4190 - val_loss: 2.6378 - val_accuracy: 0.4074\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.5148 - accuracy: 0.4195 - val_loss: 2.5344 - val_accuracy: 0.4162\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 2.4919 - accuracy: 0.4246 - val_loss: 2.5889 - val_accuracy: 0.4122\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.4714 - accuracy: 0.4296 - val_loss: 2.5164 - val_accuracy: 0.4276\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 2.4631 - accuracy: 0.4344 - val_loss: 2.5239 - val_accuracy: 0.4212\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.4505 - accuracy: 0.4335 - val_loss: 2.5308 - val_accuracy: 0.4237\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.4438 - accuracy: 0.4377 - val_loss: 2.4931 - val_accuracy: 0.4306\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.4216 - accuracy: 0.4401 - val_loss: 2.4677 - val_accuracy: 0.4360\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.4105 - accuracy: 0.4457 - val_loss: 2.5282 - val_accuracy: 0.4290\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.4036 - accuracy: 0.4459 - val_loss: 2.4728 - val_accuracy: 0.4386\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 2.3952 - accuracy: 0.4489 - val_loss: 2.4543 - val_accuracy: 0.4413\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.3721 - accuracy: 0.4539 - val_loss: 2.4173 - val_accuracy: 0.4425\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.3768 - accuracy: 0.4489 - val_loss: 2.4227 - val_accuracy: 0.4443\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 2.3683 - accuracy: 0.4558 - val_loss: 2.4379 - val_accuracy: 0.4463\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.3555 - accuracy: 0.4574 - val_loss: 2.4813 - val_accuracy: 0.4403\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 2.3460 - accuracy: 0.4610 - val_loss: 2.4365 - val_accuracy: 0.4430\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.3416 - accuracy: 0.4601 - val_loss: 2.4848 - val_accuracy: 0.4394\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.3314 - accuracy: 0.4662 - val_loss: 2.4546 - val_accuracy: 0.4428\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.3211 - accuracy: 0.4676 - val_loss: 2.4156 - val_accuracy: 0.4491\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.3186 - accuracy: 0.4638 - val_loss: 2.4381 - val_accuracy: 0.4423\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.3164 - accuracy: 0.4646 - val_loss: 2.5234 - val_accuracy: 0.4349\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 2.3112 - accuracy: 0.4655 - val_loss: 2.3982 - val_accuracy: 0.4539\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 2.3050 - accuracy: 0.4701 - val_loss: 2.4209 - val_accuracy: 0.4508\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2966 - accuracy: 0.4694 - val_loss: 2.4860 - val_accuracy: 0.4330\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2925 - accuracy: 0.4735 - val_loss: 2.4045 - val_accuracy: 0.4562\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2765 - accuracy: 0.4765 - val_loss: 2.4134 - val_accuracy: 0.4524\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 2.2735 - accuracy: 0.4747 - val_loss: 2.3895 - val_accuracy: 0.4557\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2665 - accuracy: 0.4747 - val_loss: 2.3952 - val_accuracy: 0.4574\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2606 - accuracy: 0.4817 - val_loss: 2.3909 - val_accuracy: 0.4593\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.2684 - accuracy: 0.4759 - val_loss: 2.4293 - val_accuracy: 0.4519\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 2.2585 - accuracy: 0.4791 - val_loss: 2.3787 - val_accuracy: 0.4606\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2567 - accuracy: 0.4825 - val_loss: 2.3931 - val_accuracy: 0.4547\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 2.2500 - accuracy: 0.4845 - val_loss: 2.4315 - val_accuracy: 0.4521\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2486 - accuracy: 0.4838 - val_loss: 2.3628 - val_accuracy: 0.4660\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 2.2443 - accuracy: 0.4826 - val_loss: 2.4081 - val_accuracy: 0.4546\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.2323 - accuracy: 0.4890 - val_loss: 2.4106 - val_accuracy: 0.4535\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2376 - accuracy: 0.4859 - val_loss: 2.3763 - val_accuracy: 0.4641\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.2322 - accuracy: 0.4872 - val_loss: 2.3964 - val_accuracy: 0.4597\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 2.2249 - accuracy: 0.4900 - val_loss: 2.3689 - val_accuracy: 0.4573\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2249 - accuracy: 0.4871 - val_loss: 2.3513 - val_accuracy: 0.4662\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2223 - accuracy: 0.4930 - val_loss: 2.3886 - val_accuracy: 0.4597\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2055 - accuracy: 0.4920 - val_loss: 2.3879 - val_accuracy: 0.4618\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2093 - accuracy: 0.4902 - val_loss: 2.4450 - val_accuracy: 0.4490\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 2.2056 - accuracy: 0.4923 - val_loss: 2.3778 - val_accuracy: 0.4637\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2014 - accuracy: 0.4960 - val_loss: 2.3712 - val_accuracy: 0.4630\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 2.1990 - accuracy: 0.4935 - val_loss: 2.3588 - val_accuracy: 0.4680\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2009 - accuracy: 0.4955 - val_loss: 2.3476 - val_accuracy: 0.4669\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 2.1907 - accuracy: 0.4959 - val_loss: 2.3578 - val_accuracy: 0.4729\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1969 - accuracy: 0.4964 - val_loss: 2.3285 - val_accuracy: 0.4738\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1928 - accuracy: 0.4947 - val_loss: 2.3657 - val_accuracy: 0.4650\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.1853 - accuracy: 0.4957 - val_loss: 2.4648 - val_accuracy: 0.4499\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.2004 - accuracy: 0.4991 - val_loss: 2.3615 - val_accuracy: 0.4683\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1852 - accuracy: 0.4959 - val_loss: 2.3686 - val_accuracy: 0.4706\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.1756 - accuracy: 0.5029 - val_loss: 2.3547 - val_accuracy: 0.4722\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.1752 - accuracy: 0.5014 - val_loss: 2.3938 - val_accuracy: 0.4632\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 2.1818 - accuracy: 0.5010 - val_loss: 2.3666 - val_accuracy: 0.4724\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1746 - accuracy: 0.4984 - val_loss: 2.3573 - val_accuracy: 0.4663\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1728 - accuracy: 0.5024 - val_loss: 2.4021 - val_accuracy: 0.4596\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1780 - accuracy: 0.5016 - val_loss: 2.3327 - val_accuracy: 0.4726\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1582 - accuracy: 0.5042 - val_loss: 2.3789 - val_accuracy: 0.4677\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1551 - accuracy: 0.5059 - val_loss: 2.3878 - val_accuracy: 0.4644\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 2.1582 - accuracy: 0.5025 - val_loss: 2.3555 - val_accuracy: 0.4702\n",
            "Epoch 77/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1523 - accuracy: 0.5083 - val_loss: 2.3489 - val_accuracy: 0.4716\n",
            "Epoch 78/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1563 - accuracy: 0.5050 - val_loss: 2.3652 - val_accuracy: 0.4660\n",
            "Epoch 79/100\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 2.1651 - accuracy: 0.4993 - val_loss: 2.3496 - val_accuracy: 0.4684\n",
            "Epoch 80/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1435 - accuracy: 0.5078 - val_loss: 2.3257 - val_accuracy: 0.4803\n",
            "Epoch 81/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1447 - accuracy: 0.5111 - val_loss: 2.3826 - val_accuracy: 0.4704\n",
            "Epoch 82/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1415 - accuracy: 0.5102 - val_loss: 2.3678 - val_accuracy: 0.4693\n",
            "Epoch 83/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1456 - accuracy: 0.5085 - val_loss: 2.3672 - val_accuracy: 0.4714\n",
            "Epoch 84/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1495 - accuracy: 0.5082 - val_loss: 2.3515 - val_accuracy: 0.4777\n",
            "Epoch 85/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.1367 - accuracy: 0.5098 - val_loss: 2.3361 - val_accuracy: 0.4754\n",
            "Epoch 86/100\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 2.1452 - accuracy: 0.5095 - val_loss: 2.4185 - val_accuracy: 0.4590\n",
            "Epoch 87/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1362 - accuracy: 0.5090 - val_loss: 2.3482 - val_accuracy: 0.4786\n",
            "Epoch 88/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1318 - accuracy: 0.5115 - val_loss: 2.3278 - val_accuracy: 0.4780\n",
            "Epoch 89/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1213 - accuracy: 0.5109 - val_loss: 2.3491 - val_accuracy: 0.4789\n",
            "Epoch 90/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1309 - accuracy: 0.5123 - val_loss: 2.3575 - val_accuracy: 0.4770\n",
            "Epoch 91/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1199 - accuracy: 0.5116 - val_loss: 2.3409 - val_accuracy: 0.4779\n",
            "Epoch 92/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1213 - accuracy: 0.5147 - val_loss: 2.3967 - val_accuracy: 0.4697\n",
            "Epoch 93/100\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 2.1294 - accuracy: 0.5118 - val_loss: 2.3462 - val_accuracy: 0.4692\n",
            "Epoch 94/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1319 - accuracy: 0.5123 - val_loss: 2.3341 - val_accuracy: 0.4761\n",
            "Epoch 95/100\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 2.1271 - accuracy: 0.5106 - val_loss: 2.3057 - val_accuracy: 0.4835\n",
            "Epoch 96/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1101 - accuracy: 0.5159 - val_loss: 2.3492 - val_accuracy: 0.4748\n",
            "Epoch 97/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1293 - accuracy: 0.5143 - val_loss: 2.3262 - val_accuracy: 0.4794\n",
            "Epoch 98/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1181 - accuracy: 0.5143 - val_loss: 2.3676 - val_accuracy: 0.4686\n",
            "Epoch 99/100\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 2.1282 - accuracy: 0.5145 - val_loss: 2.3061 - val_accuracy: 0.4841\n",
            "Epoch 100/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1123 - accuracy: 0.5139 - val_loss: 2.3119 - val_accuracy: 0.4803\n",
            "cifar100_down_False_BTrue.keras\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.2750 - accuracy: 0.4947\n",
            "Test Accuracy: 49.47%\n",
            "polarity: down    amsgrad: True\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_12 (Ba  (None, 32, 32, 3)         12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 128)       3584      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 32, 32, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 16, 16, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 8, 8, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 32)          18464     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 8, 8, 32)          128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 4, 4, 32)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 4, 4, 32)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273872 (1.04 MB)\n",
            "Trainable params: 273418 (1.04 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 43s 55ms/step - loss: 4.8377 - accuracy: 0.1311 - val_loss: 3.6486 - val_accuracy: 0.1894\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 3.4963 - accuracy: 0.2181 - val_loss: 3.3625 - val_accuracy: 0.2470\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 3.2496 - accuracy: 0.2663 - val_loss: 3.1532 - val_accuracy: 0.2845\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 3.0615 - accuracy: 0.3046 - val_loss: 2.9831 - val_accuracy: 0.3202\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.9447 - accuracy: 0.3294 - val_loss: 2.8824 - val_accuracy: 0.3410\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.8502 - accuracy: 0.3483 - val_loss: 2.7899 - val_accuracy: 0.3651\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.7903 - accuracy: 0.3612 - val_loss: 2.7369 - val_accuracy: 0.3727\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.7308 - accuracy: 0.3719 - val_loss: 2.7881 - val_accuracy: 0.3618\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.6859 - accuracy: 0.3845 - val_loss: 2.6479 - val_accuracy: 0.3932\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.6465 - accuracy: 0.3920 - val_loss: 2.5948 - val_accuracy: 0.4076\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.6169 - accuracy: 0.3964 - val_loss: 2.7288 - val_accuracy: 0.3807\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.5772 - accuracy: 0.4053 - val_loss: 2.5895 - val_accuracy: 0.4059\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.5535 - accuracy: 0.4117 - val_loss: 2.6079 - val_accuracy: 0.3966\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.5296 - accuracy: 0.4186 - val_loss: 2.5417 - val_accuracy: 0.4142\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.5102 - accuracy: 0.4225 - val_loss: 2.5946 - val_accuracy: 0.4111\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4986 - accuracy: 0.4244 - val_loss: 2.5181 - val_accuracy: 0.4240\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4709 - accuracy: 0.4284 - val_loss: 2.4900 - val_accuracy: 0.4260\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.4593 - accuracy: 0.4330 - val_loss: 2.4542 - val_accuracy: 0.4394\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.4368 - accuracy: 0.4372 - val_loss: 2.5157 - val_accuracy: 0.4198\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4234 - accuracy: 0.4412 - val_loss: 2.4406 - val_accuracy: 0.4343\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.4138 - accuracy: 0.4411 - val_loss: 2.4344 - val_accuracy: 0.4431\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.4019 - accuracy: 0.4439 - val_loss: 2.4668 - val_accuracy: 0.4349\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.3837 - accuracy: 0.4463 - val_loss: 2.4460 - val_accuracy: 0.4398\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3667 - accuracy: 0.4496 - val_loss: 2.4032 - val_accuracy: 0.4520\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3690 - accuracy: 0.4509 - val_loss: 2.4161 - val_accuracy: 0.4425\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3520 - accuracy: 0.4552 - val_loss: 2.4119 - val_accuracy: 0.4517\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3368 - accuracy: 0.4597 - val_loss: 2.3906 - val_accuracy: 0.4482\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3373 - accuracy: 0.4606 - val_loss: 2.4358 - val_accuracy: 0.4423\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.3197 - accuracy: 0.4614 - val_loss: 2.4079 - val_accuracy: 0.4463\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3064 - accuracy: 0.4669 - val_loss: 2.4190 - val_accuracy: 0.4442\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2998 - accuracy: 0.4648 - val_loss: 2.3848 - val_accuracy: 0.4536\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2942 - accuracy: 0.4716 - val_loss: 2.3624 - val_accuracy: 0.4678\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2920 - accuracy: 0.4708 - val_loss: 2.3781 - val_accuracy: 0.4562\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2804 - accuracy: 0.4703 - val_loss: 2.4097 - val_accuracy: 0.4522\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.2693 - accuracy: 0.4747 - val_loss: 2.3830 - val_accuracy: 0.4573\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2680 - accuracy: 0.4747 - val_loss: 2.3693 - val_accuracy: 0.4542\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2595 - accuracy: 0.4784 - val_loss: 2.3675 - val_accuracy: 0.4549\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2563 - accuracy: 0.4747 - val_loss: 2.3326 - val_accuracy: 0.4659\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2404 - accuracy: 0.4808 - val_loss: 2.3324 - val_accuracy: 0.4701\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2465 - accuracy: 0.4785 - val_loss: 2.3562 - val_accuracy: 0.4642\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2354 - accuracy: 0.4829 - val_loss: 2.3364 - val_accuracy: 0.4647\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2284 - accuracy: 0.4800 - val_loss: 2.3763 - val_accuracy: 0.4529\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2248 - accuracy: 0.4846 - val_loss: 2.3450 - val_accuracy: 0.4621\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2189 - accuracy: 0.4858 - val_loss: 2.3204 - val_accuracy: 0.4646\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2128 - accuracy: 0.4866 - val_loss: 2.3648 - val_accuracy: 0.4617\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2097 - accuracy: 0.4895 - val_loss: 2.3180 - val_accuracy: 0.4678\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2057 - accuracy: 0.4872 - val_loss: 2.3607 - val_accuracy: 0.4567\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1985 - accuracy: 0.4874 - val_loss: 2.3314 - val_accuracy: 0.4643\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2013 - accuracy: 0.4925 - val_loss: 2.3501 - val_accuracy: 0.4604\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1914 - accuracy: 0.4944 - val_loss: 2.2971 - val_accuracy: 0.4699\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1695 - accuracy: 0.4954 - val_loss: 2.3141 - val_accuracy: 0.4688\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.1831 - accuracy: 0.4926 - val_loss: 2.3548 - val_accuracy: 0.4602\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1776 - accuracy: 0.4932 - val_loss: 2.3501 - val_accuracy: 0.4617\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.1774 - accuracy: 0.4941 - val_loss: 2.3308 - val_accuracy: 0.4737\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1696 - accuracy: 0.4965 - val_loss: 2.3063 - val_accuracy: 0.4753\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1722 - accuracy: 0.4980 - val_loss: 2.2923 - val_accuracy: 0.4754\n",
            "cifar100_down_True_BTrue.keras\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.2847 - accuracy: 0.4758\n",
            "Test Accuracy: 47.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show files\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-S648Mc_KBx",
        "outputId": "7c78dd6f-d592-4165-f590-e5fc6a5e38b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar100_down_False_BTrue.keras  cifar100_up_False.keras       main.py\t    sample_data\n",
            "cifar100_down_True_BTrue.keras\t cifar100_up_True_BTrue.keras  model.py     util.py\n",
            "cifar100_up_False_BTrue.keras\t cifar100_up_True.keras        __pycache__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the downloading in files is bugged for colab\n",
        "# so this command is separate from saving\n",
        "\n",
        "files.download(\"cifar100_down_False_BTrue.keras\")\n",
        "files.download(\"cifar100_down_True_BTrue.keras\")\n",
        "files.download(\"cifar100_up_False_BTrue.keras\")\n",
        "files.download(\"cifar100_up_True_BTrue.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YGJmaujFALW9",
        "outputId": "1f750c89-b6a6-41e3-859b-670d1106caa7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bebbfc42-9c33-409f-8d66-3dfdd710a89c\", \"cifar100_down_False_BTrue.keras\", 3367037)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_507533bc-657e-4c8d-9ff6-d001fe193d53\", \"cifar100_down_True_BTrue.keras\", 4467824)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_53b90a7a-fb92-4f6d-be05-0e0eb40df722\", \"cifar100_up_False_BTrue.keras\", 8054508)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ce76a189-6395-4a32-ac31-c03480dd8d56\", \"cifar100_up_True_BTrue.keras\", 10717795)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}