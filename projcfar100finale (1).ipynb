{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile util.py\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "def exportModel(history, polarity, amsgrad, model):\n",
        "  \"\"\"\n",
        "  this function allows us to save the model in its final state\n",
        "  for later experimentation, use, and reproducability storage\n",
        "\n",
        "  NOTE: this function is designed for google colab\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  fileName=\"cifar100_\"+str(polarity)+\"_\"+str(amsgrad)+\".keras\"\n",
        "  print(fileName)\n",
        "  model.save(fileName)\n",
        "  #files.download(fileName)\n",
        "\n",
        "\n",
        "def getData(reproSeed=1):\n",
        "  \"\"\"\n",
        "  this function not only grabs the data from the source\n",
        "  but also does a true 3 way split\n",
        "  as a 2 way split is only performed by default\n",
        "  which does not provide validation data\n",
        "\n",
        "  this function also prepares the data in a way\n",
        "  that works well with our model setup\n",
        "  \"\"\"\n",
        "\n",
        "  # first split, from obtaining the data\n",
        "  (trainValImgs, trainValLabels),(testImgs, testLabels)= datasets.cifar100.load_data( )\n",
        "\n",
        "  # normalize the values because 255 format\n",
        "  # makes things difficult\n",
        "  trainValImgs = trainValImgs/255\n",
        "  testImgs = testImgs/255\n",
        "\n",
        "  #flatten to ensure compatable with later functions\n",
        "  trainValLabels = trainValLabels.ravel()\n",
        "  testLabels = testLabels.ravel()\n",
        "\n",
        "\n",
        "  # second split is needed to run testing\n",
        "  trainImgs, valImgs, trainLabels, valLabels = train_test_split(trainValImgs,\n",
        "                                                              trainValLabels,\n",
        "                                                              test_size=0.25,\n",
        "                                                              random_state=reproSeed)\n",
        "\n",
        "  return trainImgs, valImgs, trainLabels, valLabels, testImgs, testLabels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUFKHQIVvcP1",
        "outputId": "55dc19cd-8093-40b7-9138-17ddbb421646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting util.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqvD5CYRt_jY",
        "outputId": "7bd0d771-459e-430f-928b-7188ae86ec91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "def modelMaker(amsgrad= False, polarity = \"up\"):\n",
        "  \"\"\"\n",
        "  this function creates and compiles a model\n",
        "\n",
        "  there are two settings for the architecture:\n",
        "    'up'   : the convolutional layers build up in filter count\n",
        "    'down' : the convolutional layers build down on filter count\n",
        "    (all kernels are the same size)\n",
        "\n",
        "  there are two settings for hyperparamters\n",
        "    'True' : ams grad is on\n",
        "    'False': ams grad is off\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  match polarity:\n",
        "    case \"up\":\n",
        "      model = models.Sequential([\n",
        "        layers.Input(shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        #layers.Conv2D(32, 3, strides=2, padding='same', use_bias=False),\n",
        "\n",
        "        layers.Conv2D(32, 3, padding='same', use_bias=False), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(64, 3, padding='same', use_bias=False), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(128, 3, padding='same', use_bias=False), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "        layers.Flatten(),\n",
        "\n",
        "\n",
        "        layers.Dense(256, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(128, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(100, activation=\"softmax\")\n",
        "      ])\n",
        "      adamm=Adam(amsgrad=amsgrad)\n",
        "      model.compile(optimizer=adamm,\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "      return model\n",
        "\n",
        "\n",
        "    case \"down\":\n",
        "      model = models.Sequential([\n",
        "        layers.Input(shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        #layers.Conv2D(32, 3, strides=2, padding='same', use_bias=False),\n",
        "\n",
        "        layers.Conv2D(128, 3, padding='same', use_bias=False), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(64, 3, padding='same', use_bias=False), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(32, 3, padding='same', use_bias=False), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "        layers.Flatten(),\n",
        "\n",
        "\n",
        "        layers.Dense(256, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(128, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(100, activation=\"softmax\")\n",
        "      ])\n",
        "      adamm=Adam(amsgrad=amsgrad)\n",
        "      model.compile(optimizer=adamm,\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "      return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "\n",
        "from util import *\n",
        "from model import *\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mainrun(polarity, amsgrad):\n",
        "  \"\"\"\n",
        "  this function is the main run for setting up\n",
        "  fitting, testing, and exporting our model\n",
        "\n",
        "  there are some manipulatable settings\n",
        "  but nothing that should be changed between tests\n",
        "  \"\"\"\n",
        "  # seed for reproducability\n",
        "  reproSeed=1\n",
        "  # max epochs\n",
        "  epoccs=100#20#00\n",
        "  # early stopping, does not always activate\n",
        "  # due to other regularizers at play\n",
        "  callback = callbacks.EarlyStopping(monitor='loss',\n",
        "                                                patience=5,\n",
        "                                                restore_best_weights=True)\n",
        "\n",
        "  # get cifar100 fine data with full 3 way split\n",
        "  trainImgs, valImgs, trainLabels, valLabels, testImgs, testLabels = getData(reproSeed=reproSeed)\n",
        "\n",
        "  # generate the model with architecture based on up or down\n",
        "  # and amsgrad on or off\n",
        "  model = modelMaker(amsgrad=amsgrad , polarity=polarity)\n",
        "\n",
        "  # show relavant information about the model\n",
        "  print(\"polarity:\", polarity,\"   amsgrad:\",  amsgrad)\n",
        "  model.summary()\n",
        "\n",
        "  # fit the model\n",
        "  history = model.fit(\n",
        "    trainImgs, trainLabels, epochs=epoccs, validation_data=(valImgs, valLabels),\n",
        "    callbacks=[callback], batch_size=50\n",
        "  )\n",
        "\n",
        "  # download the model so you can use it later\n",
        "  exportModel(history=history, polarity=polarity, amsgrad=amsgrad, model=model)\n",
        "\n",
        "  # placeholder until we get resampled CI testacc\n",
        "  testLoss, testAcc = model.evaluate(testImgs, testLabels)\n",
        "  print(f\"Test Accuracy: {testAcc*100:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  \"\"\"\n",
        "  each of these function calls is a new test\n",
        "  we need four total\n",
        "  (two architectures two hyperparameters)\n",
        "  more can be added, and individual ones can\n",
        "  be commed out\n",
        "  since these models take a long time to train\n",
        "\n",
        "  This setup helps maintain that we change\n",
        "  what we are interested in for the experiment\n",
        "  and hold all else constant\n",
        "  \"\"\"\n",
        "\n",
        "  mainrun(polarity=\"up\", amsgrad=False)\n",
        "  mainrun(polarity=\"up\", amsgrad=True)\n",
        "  mainrun(polarity=\"down\", amsgrad=False)\n",
        "  mainrun(polarity=\"down\", amsgrad=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UfILMXtvDsc",
        "outputId": "c526a2fd-0de7-428a-a23c-cd75809b2fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPcJDqOq2ILS",
        "outputId": "0fc591e3-0120-4937-a173-70440fe3336f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-08 07:57:50.409957: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:95] Opening library: /usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2\n",
            "2024-07-08 07:57:50.410147: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:119] Libtpu path is: libtpu.so\n",
            "2024-07-08 07:57:50.458418: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-08 07:58:00.663399: I external/local_xla/xla/service/service.cc:168] XLA service 0x5b2fdf145810 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\n",
            "2024-07-08 07:58:00.663453: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): TPU, 2a886c8\n",
            "2024-07-08 07:58:00.663463: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): TPU, 2a886c8\n",
            "2024-07-08 07:58:00.663470: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (2): TPU, 2a886c8\n",
            "2024-07-08 07:58:00.663477: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (3): TPU, 2a886c8\n",
            "2024-07-08 07:58:00.663487: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (4): TPU, 2a886c8\n",
            "2024-07-08 07:58:00.663503: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (5): TPU, 2a886c8\n",
            "2024-07-08 07:58:00.663510: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (6): TPU, 2a886c8\n",
            "2024-07-08 07:58:00.663517: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (7): TPU, 2a886c8\n",
            "2024-07-08 07:58:00.663650: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.663720: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.663782: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.663837: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.663886: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.664038: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.664182: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.664345: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.664450: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.664530: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.664712: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.664804: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.664894: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.664966: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.665033: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.665169: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.665319: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.665387: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.665450: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.665534: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.665695: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.665771: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.665833: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.665912: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.665979: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.666136: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.666224: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.666291: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.666355: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.666432: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.666619: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.666717: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.666806: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.666880: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.666980: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.667165: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.667245: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.667317: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.667420: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 07:58:00.667529: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "polarity: up    amsgrad: False\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (Batch  (None, 32, 32, 3)         12        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        864       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18432     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73728     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664272 (2.53 MB)\n",
            "Trainable params: 663818 (2.53 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 27s 33ms/step - loss: 4.8830 - accuracy: 0.1404 - val_loss: 3.6748 - val_accuracy: 0.2014\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 3.4603 - accuracy: 0.2511 - val_loss: 3.2977 - val_accuracy: 0.2769\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 3.2106 - accuracy: 0.3023 - val_loss: 3.0979 - val_accuracy: 0.3294\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 3.0820 - accuracy: 0.3336 - val_loss: 3.0376 - val_accuracy: 0.3366\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.9868 - accuracy: 0.3551 - val_loss: 3.0586 - val_accuracy: 0.3381\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 2.9158 - accuracy: 0.3743 - val_loss: 2.9203 - val_accuracy: 0.3757\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.8609 - accuracy: 0.3890 - val_loss: 2.8401 - val_accuracy: 0.3818\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.8018 - accuracy: 0.4025 - val_loss: 2.8189 - val_accuracy: 0.4009\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.7723 - accuracy: 0.4104 - val_loss: 2.8701 - val_accuracy: 0.3965\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.7300 - accuracy: 0.4186 - val_loss: 2.8529 - val_accuracy: 0.3986\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.7114 - accuracy: 0.4242 - val_loss: 2.8325 - val_accuracy: 0.4002\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.6820 - accuracy: 0.4322 - val_loss: 2.8001 - val_accuracy: 0.4055\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.6516 - accuracy: 0.4323 - val_loss: 2.7400 - val_accuracy: 0.4208\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.6395 - accuracy: 0.4451 - val_loss: 2.7222 - val_accuracy: 0.4302\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.6253 - accuracy: 0.4451 - val_loss: 2.6909 - val_accuracy: 0.4318\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.6045 - accuracy: 0.4496 - val_loss: 2.7725 - val_accuracy: 0.4264\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.5886 - accuracy: 0.4517 - val_loss: 2.7312 - val_accuracy: 0.4316\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.5713 - accuracy: 0.4601 - val_loss: 2.7051 - val_accuracy: 0.4354\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.5607 - accuracy: 0.4593 - val_loss: 2.7214 - val_accuracy: 0.4310\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.5438 - accuracy: 0.4634 - val_loss: 2.6723 - val_accuracy: 0.4363\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.5353 - accuracy: 0.4696 - val_loss: 2.6937 - val_accuracy: 0.4424\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.5311 - accuracy: 0.4709 - val_loss: 2.7215 - val_accuracy: 0.4342\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.5122 - accuracy: 0.4692 - val_loss: 2.6159 - val_accuracy: 0.4578\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.5071 - accuracy: 0.4745 - val_loss: 2.7093 - val_accuracy: 0.4299\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.5056 - accuracy: 0.4753 - val_loss: 2.6621 - val_accuracy: 0.4506\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.4985 - accuracy: 0.4761 - val_loss: 2.7256 - val_accuracy: 0.4381\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.4781 - accuracy: 0.4803 - val_loss: 2.6793 - val_accuracy: 0.4414\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.4698 - accuracy: 0.4824 - val_loss: 2.6954 - val_accuracy: 0.4469\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.4738 - accuracy: 0.4816 - val_loss: 2.6369 - val_accuracy: 0.4600\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.4437 - accuracy: 0.4857 - val_loss: 2.6013 - val_accuracy: 0.4561\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.4323 - accuracy: 0.4840 - val_loss: 2.6604 - val_accuracy: 0.4529\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.4341 - accuracy: 0.4852 - val_loss: 2.5969 - val_accuracy: 0.4506\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.4042 - accuracy: 0.4870 - val_loss: 2.6041 - val_accuracy: 0.4593\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.3937 - accuracy: 0.4895 - val_loss: 2.5540 - val_accuracy: 0.4537\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3780 - accuracy: 0.4913 - val_loss: 2.6286 - val_accuracy: 0.4495\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.3694 - accuracy: 0.4908 - val_loss: 2.5277 - val_accuracy: 0.4612\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.3432 - accuracy: 0.4919 - val_loss: 2.5115 - val_accuracy: 0.4630\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.3361 - accuracy: 0.4926 - val_loss: 2.5811 - val_accuracy: 0.4496\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3114 - accuracy: 0.4989 - val_loss: 2.5642 - val_accuracy: 0.4525\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.3038 - accuracy: 0.4995 - val_loss: 2.5198 - val_accuracy: 0.4630\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.2981 - accuracy: 0.5001 - val_loss: 2.4711 - val_accuracy: 0.4681\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.2849 - accuracy: 0.5028 - val_loss: 2.4628 - val_accuracy: 0.4750\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.2940 - accuracy: 0.4994 - val_loss: 2.5095 - val_accuracy: 0.4690\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2840 - accuracy: 0.5018 - val_loss: 2.5516 - val_accuracy: 0.4573\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2649 - accuracy: 0.5096 - val_loss: 2.5666 - val_accuracy: 0.4538\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.2632 - accuracy: 0.5091 - val_loss: 2.5184 - val_accuracy: 0.4614\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2483 - accuracy: 0.5102 - val_loss: 2.5271 - val_accuracy: 0.4626\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2544 - accuracy: 0.5106 - val_loss: 2.5160 - val_accuracy: 0.4577\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2453 - accuracy: 0.5119 - val_loss: 2.4699 - val_accuracy: 0.4740\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.2360 - accuracy: 0.5126 - val_loss: 2.4953 - val_accuracy: 0.4668\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.2411 - accuracy: 0.5122 - val_loss: 2.4997 - val_accuracy: 0.4670\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2407 - accuracy: 0.5146 - val_loss: 2.5135 - val_accuracy: 0.4594\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.2318 - accuracy: 0.5122 - val_loss: 2.5734 - val_accuracy: 0.4515\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2302 - accuracy: 0.5146 - val_loss: 2.4621 - val_accuracy: 0.4766\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.2254 - accuracy: 0.5126 - val_loss: 2.4516 - val_accuracy: 0.4830\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.2199 - accuracy: 0.5147 - val_loss: 2.4588 - val_accuracy: 0.4728\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.2210 - accuracy: 0.5139 - val_loss: 2.5873 - val_accuracy: 0.4481\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.2130 - accuracy: 0.5163 - val_loss: 2.4903 - val_accuracy: 0.4658\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.2123 - accuracy: 0.5166 - val_loss: 2.4400 - val_accuracy: 0.4780\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.2094 - accuracy: 0.5190 - val_loss: 2.4647 - val_accuracy: 0.4758\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.2069 - accuracy: 0.5170 - val_loss: 2.4321 - val_accuracy: 0.4797\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.1996 - accuracy: 0.5219 - val_loss: 2.4976 - val_accuracy: 0.4641\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.2018 - accuracy: 0.5194 - val_loss: 2.4800 - val_accuracy: 0.4730\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.2010 - accuracy: 0.5168 - val_loss: 2.4994 - val_accuracy: 0.4688\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1932 - accuracy: 0.5220 - val_loss: 2.4697 - val_accuracy: 0.4749\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1894 - accuracy: 0.5251 - val_loss: 2.4546 - val_accuracy: 0.4830\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1917 - accuracy: 0.5234 - val_loss: 2.4790 - val_accuracy: 0.4681\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1956 - accuracy: 0.5226 - val_loss: 2.4438 - val_accuracy: 0.4826\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.1785 - accuracy: 0.5267 - val_loss: 2.4454 - val_accuracy: 0.4832\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1779 - accuracy: 0.5292 - val_loss: 2.4825 - val_accuracy: 0.4769\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1819 - accuracy: 0.5239 - val_loss: 2.4844 - val_accuracy: 0.4735\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1800 - accuracy: 0.5265 - val_loss: 2.5179 - val_accuracy: 0.4678\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1711 - accuracy: 0.5270 - val_loss: 2.4744 - val_accuracy: 0.4802\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.1763 - accuracy: 0.5250 - val_loss: 2.4508 - val_accuracy: 0.4810\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1657 - accuracy: 0.5262 - val_loss: 2.4711 - val_accuracy: 0.4758\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1647 - accuracy: 0.5299 - val_loss: 2.4594 - val_accuracy: 0.4734\n",
            "Epoch 77/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.1622 - accuracy: 0.5293 - val_loss: 2.4666 - val_accuracy: 0.4810\n",
            "Epoch 78/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1657 - accuracy: 0.5283 - val_loss: 2.4679 - val_accuracy: 0.4776\n",
            "Epoch 79/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1566 - accuracy: 0.5287 - val_loss: 2.4714 - val_accuracy: 0.4798\n",
            "Epoch 80/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1594 - accuracy: 0.5294 - val_loss: 2.4607 - val_accuracy: 0.4835\n",
            "Epoch 81/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1636 - accuracy: 0.5322 - val_loss: 2.4948 - val_accuracy: 0.4674\n",
            "Epoch 82/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1496 - accuracy: 0.5318 - val_loss: 2.4764 - val_accuracy: 0.4801\n",
            "Epoch 83/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1540 - accuracy: 0.5321 - val_loss: 2.4108 - val_accuracy: 0.4886\n",
            "Epoch 84/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1483 - accuracy: 0.5318 - val_loss: 2.4354 - val_accuracy: 0.4845\n",
            "Epoch 85/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1598 - accuracy: 0.5329 - val_loss: 2.5100 - val_accuracy: 0.4760\n",
            "Epoch 86/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1545 - accuracy: 0.5335 - val_loss: 2.4452 - val_accuracy: 0.4839\n",
            "Epoch 87/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.1532 - accuracy: 0.5314 - val_loss: 2.4466 - val_accuracy: 0.4871\n",
            "Epoch 88/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.1488 - accuracy: 0.5310 - val_loss: 2.4317 - val_accuracy: 0.4893\n",
            "Epoch 89/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1469 - accuracy: 0.5357 - val_loss: 2.4513 - val_accuracy: 0.4826\n",
            "Epoch 90/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1418 - accuracy: 0.5346 - val_loss: 2.4242 - val_accuracy: 0.4921\n",
            "Epoch 91/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.1414 - accuracy: 0.5367 - val_loss: 2.4256 - val_accuracy: 0.4871\n",
            "Epoch 92/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1391 - accuracy: 0.5359 - val_loss: 2.4891 - val_accuracy: 0.4802\n",
            "Epoch 93/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1392 - accuracy: 0.5369 - val_loss: 2.5243 - val_accuracy: 0.4648\n",
            "Epoch 94/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1403 - accuracy: 0.5376 - val_loss: 2.4647 - val_accuracy: 0.4826\n",
            "Epoch 95/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1326 - accuracy: 0.5385 - val_loss: 2.4214 - val_accuracy: 0.4914\n",
            "Epoch 96/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1397 - accuracy: 0.5350 - val_loss: 2.4136 - val_accuracy: 0.4890\n",
            "Epoch 97/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.1307 - accuracy: 0.5388 - val_loss: 2.4570 - val_accuracy: 0.4923\n",
            "Epoch 98/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1264 - accuracy: 0.5391 - val_loss: 2.4331 - val_accuracy: 0.4814\n",
            "Epoch 99/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.1344 - accuracy: 0.5359 - val_loss: 2.4183 - val_accuracy: 0.4922\n",
            "Epoch 100/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.1281 - accuracy: 0.5398 - val_loss: 2.4638 - val_accuracy: 0.4764\n",
            "cifar100_up_False.keras\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.4322 - accuracy: 0.4855\n",
            "Test Accuracy: 48.55%\n",
            "polarity: up    amsgrad: True\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_4 (Bat  (None, 32, 32, 3)         12        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 32)        864       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 16, 64)        18432     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         73728     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664272 (2.53 MB)\n",
            "Trainable params: 663818 (2.53 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 27s 34ms/step - loss: 4.9002 - accuracy: 0.1401 - val_loss: 3.8252 - val_accuracy: 0.1792\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 3.4766 - accuracy: 0.2437 - val_loss: 3.3132 - val_accuracy: 0.2770\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 3.2127 - accuracy: 0.3030 - val_loss: 3.0901 - val_accuracy: 0.3254\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 3.0634 - accuracy: 0.3345 - val_loss: 3.0420 - val_accuracy: 0.3483\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.9585 - accuracy: 0.3597 - val_loss: 2.9236 - val_accuracy: 0.3764\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.8744 - accuracy: 0.3771 - val_loss: 2.8524 - val_accuracy: 0.3893\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.8136 - accuracy: 0.3942 - val_loss: 2.8241 - val_accuracy: 0.3882\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.7751 - accuracy: 0.4003 - val_loss: 2.8441 - val_accuracy: 0.3945\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.7410 - accuracy: 0.4116 - val_loss: 2.7923 - val_accuracy: 0.4069\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.6991 - accuracy: 0.4209 - val_loss: 2.7419 - val_accuracy: 0.4158\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.6579 - accuracy: 0.4305 - val_loss: 2.7499 - val_accuracy: 0.4167\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.6408 - accuracy: 0.4357 - val_loss: 2.7163 - val_accuracy: 0.4217\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.6172 - accuracy: 0.4438 - val_loss: 2.7009 - val_accuracy: 0.4242\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.5979 - accuracy: 0.4469 - val_loss: 2.7064 - val_accuracy: 0.4294\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.5682 - accuracy: 0.4522 - val_loss: 2.6356 - val_accuracy: 0.4381\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.5527 - accuracy: 0.4607 - val_loss: 2.6923 - val_accuracy: 0.4278\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.5328 - accuracy: 0.4603 - val_loss: 2.6682 - val_accuracy: 0.4344\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.5174 - accuracy: 0.4625 - val_loss: 2.6415 - val_accuracy: 0.4430\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.5034 - accuracy: 0.4657 - val_loss: 2.6521 - val_accuracy: 0.4421\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.4924 - accuracy: 0.4674 - val_loss: 2.5886 - val_accuracy: 0.4620\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.4822 - accuracy: 0.4738 - val_loss: 2.6398 - val_accuracy: 0.4457\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.4665 - accuracy: 0.4767 - val_loss: 2.6356 - val_accuracy: 0.4512\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.4631 - accuracy: 0.4774 - val_loss: 2.6704 - val_accuracy: 0.4431\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.4589 - accuracy: 0.4788 - val_loss: 2.6800 - val_accuracy: 0.4414\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.4354 - accuracy: 0.4838 - val_loss: 2.6339 - val_accuracy: 0.4508\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.4432 - accuracy: 0.4837 - val_loss: 2.6463 - val_accuracy: 0.4525\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.4276 - accuracy: 0.4883 - val_loss: 2.5737 - val_accuracy: 0.4608\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.4010 - accuracy: 0.4915 - val_loss: 2.5783 - val_accuracy: 0.4666\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.4007 - accuracy: 0.4918 - val_loss: 2.5788 - val_accuracy: 0.4582\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.3922 - accuracy: 0.4947 - val_loss: 2.5806 - val_accuracy: 0.4638\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3858 - accuracy: 0.4970 - val_loss: 2.5960 - val_accuracy: 0.4600\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.3815 - accuracy: 0.4963 - val_loss: 2.6607 - val_accuracy: 0.4486\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3632 - accuracy: 0.4989 - val_loss: 2.5573 - val_accuracy: 0.4643\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3604 - accuracy: 0.4996 - val_loss: 2.5486 - val_accuracy: 0.4722\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3573 - accuracy: 0.5000 - val_loss: 2.5645 - val_accuracy: 0.4681\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3619 - accuracy: 0.5027 - val_loss: 2.5517 - val_accuracy: 0.4688\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3428 - accuracy: 0.5059 - val_loss: 2.5823 - val_accuracy: 0.4677\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3416 - accuracy: 0.5078 - val_loss: 2.5961 - val_accuracy: 0.4651\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.3531 - accuracy: 0.5046 - val_loss: 2.5779 - val_accuracy: 0.4680\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.3389 - accuracy: 0.5105 - val_loss: 2.6268 - val_accuracy: 0.4546\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3253 - accuracy: 0.5141 - val_loss: 2.5942 - val_accuracy: 0.4602\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.3252 - accuracy: 0.5132 - val_loss: 2.6268 - val_accuracy: 0.4598\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3265 - accuracy: 0.5127 - val_loss: 2.5887 - val_accuracy: 0.4634\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3182 - accuracy: 0.5137 - val_loss: 2.5361 - val_accuracy: 0.4720\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.3144 - accuracy: 0.5124 - val_loss: 2.5366 - val_accuracy: 0.4766\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2971 - accuracy: 0.5159 - val_loss: 2.5205 - val_accuracy: 0.4743\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2894 - accuracy: 0.5177 - val_loss: 2.5451 - val_accuracy: 0.4746\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2949 - accuracy: 0.5167 - val_loss: 2.5360 - val_accuracy: 0.4738\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2965 - accuracy: 0.5186 - val_loss: 2.5369 - val_accuracy: 0.4718\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2981 - accuracy: 0.5187 - val_loss: 2.5375 - val_accuracy: 0.4792\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2834 - accuracy: 0.5224 - val_loss: 2.5752 - val_accuracy: 0.4678\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2938 - accuracy: 0.5198 - val_loss: 2.5031 - val_accuracy: 0.4815\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2669 - accuracy: 0.5244 - val_loss: 2.5298 - val_accuracy: 0.4757\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2790 - accuracy: 0.5220 - val_loss: 2.5668 - val_accuracy: 0.4702\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2853 - accuracy: 0.5223 - val_loss: 2.5493 - val_accuracy: 0.4766\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 2.2678 - accuracy: 0.5256 - val_loss: 2.5729 - val_accuracy: 0.4691\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2637 - accuracy: 0.5245 - val_loss: 2.5518 - val_accuracy: 0.4750\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2541 - accuracy: 0.5248 - val_loss: 2.4934 - val_accuracy: 0.4836\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.2559 - accuracy: 0.5226 - val_loss: 2.5179 - val_accuracy: 0.4840\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2641 - accuracy: 0.5252 - val_loss: 2.5205 - val_accuracy: 0.4815\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.2464 - accuracy: 0.5299 - val_loss: 2.5294 - val_accuracy: 0.4769\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.2424 - accuracy: 0.5305 - val_loss: 2.5225 - val_accuracy: 0.4765\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2464 - accuracy: 0.5294 - val_loss: 2.5367 - val_accuracy: 0.4786\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2534 - accuracy: 0.5283 - val_loss: 2.5249 - val_accuracy: 0.4827\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 2.2519 - accuracy: 0.5282 - val_loss: 2.4886 - val_accuracy: 0.4899\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2456 - accuracy: 0.5334 - val_loss: 2.5309 - val_accuracy: 0.4790\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.2483 - accuracy: 0.5306 - val_loss: 2.5913 - val_accuracy: 0.4708\n",
            "cifar100_up_True.keras\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.4820 - accuracy: 0.4907\n",
            "Test Accuracy: 49.07%\n",
            "polarity: down    amsgrad: False\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_8 (Bat  (None, 32, 32, 3)         12        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 128)       3456      \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 32, 32, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 16, 16, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 64)        73728     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 8, 8, 32)          18432     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 8, 8, 32)          128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 4, 4, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 4, 4, 32)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273648 (1.04 MB)\n",
            "Trainable params: 273194 (1.04 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 42s 54ms/step - loss: 4.8170 - accuracy: 0.1283 - val_loss: 3.6808 - val_accuracy: 0.1802\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 3.4955 - accuracy: 0.2163 - val_loss: 3.3239 - val_accuracy: 0.2457\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 3.2373 - accuracy: 0.2658 - val_loss: 3.0617 - val_accuracy: 0.3033\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 3.0723 - accuracy: 0.2997 - val_loss: 2.9740 - val_accuracy: 0.3162\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.9695 - accuracy: 0.3256 - val_loss: 2.8914 - val_accuracy: 0.3395\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.8839 - accuracy: 0.3420 - val_loss: 2.8716 - val_accuracy: 0.3401\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.8171 - accuracy: 0.3578 - val_loss: 2.7997 - val_accuracy: 0.3646\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.7631 - accuracy: 0.3683 - val_loss: 2.7344 - val_accuracy: 0.3718\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.7228 - accuracy: 0.3765 - val_loss: 2.7026 - val_accuracy: 0.3871\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.6742 - accuracy: 0.3866 - val_loss: 2.6403 - val_accuracy: 0.3969\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.6480 - accuracy: 0.3927 - val_loss: 2.6324 - val_accuracy: 0.4037\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.6130 - accuracy: 0.4011 - val_loss: 2.6217 - val_accuracy: 0.3997\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.5862 - accuracy: 0.4062 - val_loss: 2.6050 - val_accuracy: 0.4057\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 2.5696 - accuracy: 0.4084 - val_loss: 2.5825 - val_accuracy: 0.4099\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.5416 - accuracy: 0.4172 - val_loss: 2.5596 - val_accuracy: 0.4142\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 2.5250 - accuracy: 0.4201 - val_loss: 2.5962 - val_accuracy: 0.4030\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.5080 - accuracy: 0.4234 - val_loss: 2.5605 - val_accuracy: 0.4207\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.4941 - accuracy: 0.4260 - val_loss: 2.5398 - val_accuracy: 0.4228\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4775 - accuracy: 0.4313 - val_loss: 2.5191 - val_accuracy: 0.4258\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.4632 - accuracy: 0.4367 - val_loss: 2.4723 - val_accuracy: 0.4394\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.4467 - accuracy: 0.4362 - val_loss: 2.5214 - val_accuracy: 0.4299\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.4368 - accuracy: 0.4387 - val_loss: 2.5231 - val_accuracy: 0.4255\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.4275 - accuracy: 0.4454 - val_loss: 2.5485 - val_accuracy: 0.4206\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.4110 - accuracy: 0.4462 - val_loss: 2.4941 - val_accuracy: 0.4351\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.4109 - accuracy: 0.4474 - val_loss: 2.5053 - val_accuracy: 0.4330\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3907 - accuracy: 0.4497 - val_loss: 2.4356 - val_accuracy: 0.4447\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.3939 - accuracy: 0.4512 - val_loss: 2.4577 - val_accuracy: 0.4394\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.3750 - accuracy: 0.4562 - val_loss: 2.4329 - val_accuracy: 0.4478\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3721 - accuracy: 0.4541 - val_loss: 2.4295 - val_accuracy: 0.4470\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3557 - accuracy: 0.4594 - val_loss: 2.4114 - val_accuracy: 0.4582\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3540 - accuracy: 0.4609 - val_loss: 2.4495 - val_accuracy: 0.4491\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3474 - accuracy: 0.4615 - val_loss: 2.4479 - val_accuracy: 0.4430\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 2.3383 - accuracy: 0.4621 - val_loss: 2.4404 - val_accuracy: 0.4435\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3318 - accuracy: 0.4665 - val_loss: 2.4176 - val_accuracy: 0.4530\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.3170 - accuracy: 0.4691 - val_loss: 2.3956 - val_accuracy: 0.4601\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 2.3203 - accuracy: 0.4691 - val_loss: 2.4255 - val_accuracy: 0.4520\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 39s 51ms/step - loss: 2.3171 - accuracy: 0.4724 - val_loss: 2.3975 - val_accuracy: 0.4535\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3082 - accuracy: 0.4690 - val_loss: 2.4289 - val_accuracy: 0.4531\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2996 - accuracy: 0.4751 - val_loss: 2.4226 - val_accuracy: 0.4510\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3020 - accuracy: 0.4722 - val_loss: 2.4161 - val_accuracy: 0.4574\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2972 - accuracy: 0.4726 - val_loss: 2.3893 - val_accuracy: 0.4588\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2864 - accuracy: 0.4752 - val_loss: 2.4108 - val_accuracy: 0.4557\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2852 - accuracy: 0.4772 - val_loss: 2.3652 - val_accuracy: 0.4642\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2727 - accuracy: 0.4789 - val_loss: 2.4157 - val_accuracy: 0.4575\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2736 - accuracy: 0.4804 - val_loss: 2.4688 - val_accuracy: 0.4439\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2748 - accuracy: 0.4799 - val_loss: 2.4349 - val_accuracy: 0.4549\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2628 - accuracy: 0.4819 - val_loss: 2.3490 - val_accuracy: 0.4662\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2663 - accuracy: 0.4802 - val_loss: 2.3764 - val_accuracy: 0.4646\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2558 - accuracy: 0.4858 - val_loss: 2.3981 - val_accuracy: 0.4584\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2474 - accuracy: 0.4837 - val_loss: 2.3520 - val_accuracy: 0.4642\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2454 - accuracy: 0.4873 - val_loss: 2.3813 - val_accuracy: 0.4637\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2334 - accuracy: 0.4892 - val_loss: 2.3959 - val_accuracy: 0.4610\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2367 - accuracy: 0.4854 - val_loss: 2.3885 - val_accuracy: 0.4634\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2331 - accuracy: 0.4900 - val_loss: 2.4107 - val_accuracy: 0.4569\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2417 - accuracy: 0.4852 - val_loss: 2.3688 - val_accuracy: 0.4662\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2163 - accuracy: 0.4934 - val_loss: 2.4301 - val_accuracy: 0.4589\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2367 - accuracy: 0.4895 - val_loss: 2.3786 - val_accuracy: 0.4682\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2267 - accuracy: 0.4903 - val_loss: 2.4012 - val_accuracy: 0.4611\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2100 - accuracy: 0.4925 - val_loss: 2.3686 - val_accuracy: 0.4653\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2067 - accuracy: 0.4934 - val_loss: 2.3974 - val_accuracy: 0.4601\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 2.2154 - accuracy: 0.4958 - val_loss: 2.3949 - val_accuracy: 0.4638\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2085 - accuracy: 0.4926 - val_loss: 2.3715 - val_accuracy: 0.4680\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2010 - accuracy: 0.4961 - val_loss: 2.3894 - val_accuracy: 0.4631\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2001 - accuracy: 0.4948 - val_loss: 2.3688 - val_accuracy: 0.4679\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 2.1978 - accuracy: 0.4960 - val_loss: 2.4280 - val_accuracy: 0.4574\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1879 - accuracy: 0.5009 - val_loss: 2.3592 - val_accuracy: 0.4658\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1883 - accuracy: 0.5011 - val_loss: 2.3559 - val_accuracy: 0.4694\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 39s 51ms/step - loss: 2.1893 - accuracy: 0.5011 - val_loss: 2.3692 - val_accuracy: 0.4697\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1909 - accuracy: 0.5010 - val_loss: 2.3936 - val_accuracy: 0.4588\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1844 - accuracy: 0.5006 - val_loss: 2.3655 - val_accuracy: 0.4700\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 2.1774 - accuracy: 0.5043 - val_loss: 2.3580 - val_accuracy: 0.4757\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1847 - accuracy: 0.5011 - val_loss: 2.3584 - val_accuracy: 0.4711\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1798 - accuracy: 0.5013 - val_loss: 2.3957 - val_accuracy: 0.4585\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1810 - accuracy: 0.5007 - val_loss: 2.3530 - val_accuracy: 0.4745\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1748 - accuracy: 0.5026 - val_loss: 2.3595 - val_accuracy: 0.4674\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1643 - accuracy: 0.5052 - val_loss: 2.3926 - val_accuracy: 0.4707\n",
            "Epoch 77/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1743 - accuracy: 0.5045 - val_loss: 2.3530 - val_accuracy: 0.4741\n",
            "Epoch 78/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 2.1653 - accuracy: 0.5062 - val_loss: 2.3339 - val_accuracy: 0.4762\n",
            "Epoch 79/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 2.1614 - accuracy: 0.5074 - val_loss: 2.3937 - val_accuracy: 0.4681\n",
            "Epoch 80/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.1700 - accuracy: 0.5062 - val_loss: 2.3493 - val_accuracy: 0.4779\n",
            "Epoch 81/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 2.1578 - accuracy: 0.5125 - val_loss: 2.3522 - val_accuracy: 0.4710\n",
            "Epoch 82/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1524 - accuracy: 0.5059 - val_loss: 2.3537 - val_accuracy: 0.4751\n",
            "Epoch 83/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1610 - accuracy: 0.5068 - val_loss: 2.3481 - val_accuracy: 0.4748\n",
            "Epoch 84/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1594 - accuracy: 0.5057 - val_loss: 2.3403 - val_accuracy: 0.4748\n",
            "Epoch 85/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1486 - accuracy: 0.5059 - val_loss: 2.4079 - val_accuracy: 0.4650\n",
            "Epoch 86/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 2.1470 - accuracy: 0.5101 - val_loss: 2.3398 - val_accuracy: 0.4760\n",
            "Epoch 87/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1491 - accuracy: 0.5116 - val_loss: 2.3391 - val_accuracy: 0.4754\n",
            "Epoch 88/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1461 - accuracy: 0.5103 - val_loss: 2.3809 - val_accuracy: 0.4694\n",
            "Epoch 89/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1467 - accuracy: 0.5091 - val_loss: 2.3670 - val_accuracy: 0.4710\n",
            "Epoch 90/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1505 - accuracy: 0.5100 - val_loss: 2.3334 - val_accuracy: 0.4760\n",
            "Epoch 91/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1285 - accuracy: 0.5107 - val_loss: 2.3938 - val_accuracy: 0.4640\n",
            "Epoch 92/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1336 - accuracy: 0.5121 - val_loss: 2.3610 - val_accuracy: 0.4746\n",
            "Epoch 93/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1459 - accuracy: 0.5081 - val_loss: 2.3247 - val_accuracy: 0.4775\n",
            "Epoch 94/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1337 - accuracy: 0.5107 - val_loss: 2.3863 - val_accuracy: 0.4676\n",
            "Epoch 95/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1353 - accuracy: 0.5114 - val_loss: 2.3500 - val_accuracy: 0.4753\n",
            "Epoch 96/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1327 - accuracy: 0.5139 - val_loss: 2.3057 - val_accuracy: 0.4820\n",
            "cifar100_down_False.keras\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.3628 - accuracy: 0.4788\n",
            "Test Accuracy: 47.88%\n",
            "polarity: down    amsgrad: True\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_12 (Ba  (None, 32, 32, 3)         12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 128)       3456      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 32, 32, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 16, 16, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 64)        73728     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 8, 8, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 32)          18432     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 8, 8, 32)          128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 4, 4, 32)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 4, 4, 32)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273648 (1.04 MB)\n",
            "Trainable params: 273194 (1.04 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 42s 53ms/step - loss: 4.8068 - accuracy: 0.1357 - val_loss: 3.5906 - val_accuracy: 0.1994\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 3.4807 - accuracy: 0.2229 - val_loss: 3.2877 - val_accuracy: 0.2550\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 3.2153 - accuracy: 0.2741 - val_loss: 3.0347 - val_accuracy: 0.2994\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 3.0428 - accuracy: 0.3076 - val_loss: 2.9145 - val_accuracy: 0.3355\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.9324 - accuracy: 0.3286 - val_loss: 2.9072 - val_accuracy: 0.3362\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.8528 - accuracy: 0.3448 - val_loss: 2.7417 - val_accuracy: 0.3751\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 39s 51ms/step - loss: 2.7768 - accuracy: 0.3592 - val_loss: 2.6764 - val_accuracy: 0.3895\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.7297 - accuracy: 0.3735 - val_loss: 2.7226 - val_accuracy: 0.3815\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.6864 - accuracy: 0.3806 - val_loss: 2.6205 - val_accuracy: 0.3996\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.6434 - accuracy: 0.3914 - val_loss: 2.6278 - val_accuracy: 0.3963\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.6078 - accuracy: 0.4001 - val_loss: 2.6386 - val_accuracy: 0.3913\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.5813 - accuracy: 0.4010 - val_loss: 2.5672 - val_accuracy: 0.4040\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.5587 - accuracy: 0.4093 - val_loss: 2.5301 - val_accuracy: 0.4219\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.5331 - accuracy: 0.4091 - val_loss: 2.5149 - val_accuracy: 0.4187\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.5158 - accuracy: 0.4167 - val_loss: 2.5180 - val_accuracy: 0.4219\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.4965 - accuracy: 0.4235 - val_loss: 2.4929 - val_accuracy: 0.4333\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.4734 - accuracy: 0.4251 - val_loss: 2.4849 - val_accuracy: 0.4242\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.4563 - accuracy: 0.4304 - val_loss: 2.5497 - val_accuracy: 0.4162\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.4543 - accuracy: 0.4329 - val_loss: 2.4875 - val_accuracy: 0.4249\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.4282 - accuracy: 0.4344 - val_loss: 2.4846 - val_accuracy: 0.4256\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.4224 - accuracy: 0.4395 - val_loss: 2.4597 - val_accuracy: 0.4304\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.4125 - accuracy: 0.4426 - val_loss: 2.4435 - val_accuracy: 0.4402\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3903 - accuracy: 0.4450 - val_loss: 2.4336 - val_accuracy: 0.4406\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3889 - accuracy: 0.4469 - val_loss: 2.4159 - val_accuracy: 0.4457\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3759 - accuracy: 0.4469 - val_loss: 2.4174 - val_accuracy: 0.4453\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3651 - accuracy: 0.4488 - val_loss: 2.4056 - val_accuracy: 0.4470\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.3613 - accuracy: 0.4508 - val_loss: 2.4592 - val_accuracy: 0.4349\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3525 - accuracy: 0.4530 - val_loss: 2.4283 - val_accuracy: 0.4450\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3386 - accuracy: 0.4565 - val_loss: 2.4094 - val_accuracy: 0.4471\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3325 - accuracy: 0.4579 - val_loss: 2.4743 - val_accuracy: 0.4340\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3241 - accuracy: 0.4590 - val_loss: 2.4808 - val_accuracy: 0.4338\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.3128 - accuracy: 0.4624 - val_loss: 2.4291 - val_accuracy: 0.4436\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.3077 - accuracy: 0.4634 - val_loss: 2.3947 - val_accuracy: 0.4556\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2999 - accuracy: 0.4661 - val_loss: 2.4142 - val_accuracy: 0.4516\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 39s 51ms/step - loss: 2.2979 - accuracy: 0.4649 - val_loss: 2.3724 - val_accuracy: 0.4583\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2851 - accuracy: 0.4655 - val_loss: 2.3680 - val_accuracy: 0.4550\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.2779 - accuracy: 0.4698 - val_loss: 2.3878 - val_accuracy: 0.4479\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2717 - accuracy: 0.4719 - val_loss: 2.3528 - val_accuracy: 0.4650\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2748 - accuracy: 0.4702 - val_loss: 2.3664 - val_accuracy: 0.4609\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2696 - accuracy: 0.4768 - val_loss: 2.3289 - val_accuracy: 0.4701\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2611 - accuracy: 0.4745 - val_loss: 2.3960 - val_accuracy: 0.4522\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.2584 - accuracy: 0.4760 - val_loss: 2.3499 - val_accuracy: 0.4632\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2481 - accuracy: 0.4817 - val_loss: 2.3713 - val_accuracy: 0.4625\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2416 - accuracy: 0.4790 - val_loss: 2.3560 - val_accuracy: 0.4614\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 39s 51ms/step - loss: 2.2346 - accuracy: 0.4795 - val_loss: 2.3184 - val_accuracy: 0.4701\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2333 - accuracy: 0.4817 - val_loss: 2.3498 - val_accuracy: 0.4596\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 39s 51ms/step - loss: 2.2325 - accuracy: 0.4812 - val_loss: 2.3285 - val_accuracy: 0.4655\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 39s 51ms/step - loss: 2.2286 - accuracy: 0.4809 - val_loss: 2.3694 - val_accuracy: 0.4581\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2258 - accuracy: 0.4803 - val_loss: 2.3251 - val_accuracy: 0.4666\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2116 - accuracy: 0.4866 - val_loss: 2.3200 - val_accuracy: 0.4703\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2032 - accuracy: 0.4856 - val_loss: 2.3614 - val_accuracy: 0.4610\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.2034 - accuracy: 0.4883 - val_loss: 2.3444 - val_accuracy: 0.4618\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2036 - accuracy: 0.4860 - val_loss: 2.3000 - val_accuracy: 0.4770\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1977 - accuracy: 0.4855 - val_loss: 2.3417 - val_accuracy: 0.4682\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1989 - accuracy: 0.4906 - val_loss: 2.3159 - val_accuracy: 0.4695\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1926 - accuracy: 0.4889 - val_loss: 2.3492 - val_accuracy: 0.4668\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1798 - accuracy: 0.4923 - val_loss: 2.3247 - val_accuracy: 0.4703\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1842 - accuracy: 0.4923 - val_loss: 2.3039 - val_accuracy: 0.4742\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1814 - accuracy: 0.4941 - val_loss: 2.3221 - val_accuracy: 0.4704\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1717 - accuracy: 0.4939 - val_loss: 2.3454 - val_accuracy: 0.4662\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1771 - accuracy: 0.4939 - val_loss: 2.3354 - val_accuracy: 0.4746\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1775 - accuracy: 0.4964 - val_loss: 2.2841 - val_accuracy: 0.4782\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1734 - accuracy: 0.4952 - val_loss: 2.3284 - val_accuracy: 0.4752\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1686 - accuracy: 0.4956 - val_loss: 2.3249 - val_accuracy: 0.4739\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1633 - accuracy: 0.4977 - val_loss: 2.3469 - val_accuracy: 0.4701\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 39s 51ms/step - loss: 2.1651 - accuracy: 0.4953 - val_loss: 2.3336 - val_accuracy: 0.4680\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1549 - accuracy: 0.5014 - val_loss: 2.2855 - val_accuracy: 0.4790\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1549 - accuracy: 0.5006 - val_loss: 2.3127 - val_accuracy: 0.4770\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1448 - accuracy: 0.5018 - val_loss: 2.3122 - val_accuracy: 0.4740\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1440 - accuracy: 0.5026 - val_loss: 2.2912 - val_accuracy: 0.4749\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1497 - accuracy: 0.5017 - val_loss: 2.2922 - val_accuracy: 0.4762\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1397 - accuracy: 0.5035 - val_loss: 2.3004 - val_accuracy: 0.4754\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1450 - accuracy: 0.5040 - val_loss: 2.3110 - val_accuracy: 0.4714\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1380 - accuracy: 0.5013 - val_loss: 2.2953 - val_accuracy: 0.4735\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1392 - accuracy: 0.5027 - val_loss: 2.2601 - val_accuracy: 0.4878\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1278 - accuracy: 0.5034 - val_loss: 2.3097 - val_accuracy: 0.4758\n",
            "Epoch 77/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1205 - accuracy: 0.5077 - val_loss: 2.3428 - val_accuracy: 0.4585\n",
            "Epoch 78/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1262 - accuracy: 0.5090 - val_loss: 2.2652 - val_accuracy: 0.4880\n",
            "Epoch 79/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.1162 - accuracy: 0.5078 - val_loss: 2.3081 - val_accuracy: 0.4737\n",
            "Epoch 80/100\n",
            "750/750 [==============================] - 39s 51ms/step - loss: 2.1213 - accuracy: 0.5083 - val_loss: 2.3196 - val_accuracy: 0.4738\n",
            "Epoch 81/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1252 - accuracy: 0.5045 - val_loss: 2.2678 - val_accuracy: 0.4843\n",
            "Epoch 82/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1282 - accuracy: 0.5045 - val_loss: 2.3082 - val_accuracy: 0.4746\n",
            "Epoch 83/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1193 - accuracy: 0.5069 - val_loss: 2.2890 - val_accuracy: 0.4816\n",
            "Epoch 84/100\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.1219 - accuracy: 0.5056 - val_loss: 2.3217 - val_accuracy: 0.4675\n",
            "cifar100_down_True.keras\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.2638 - accuracy: 0.4837\n",
            "Test Accuracy: 48.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show files\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-S648Mc_KBx",
        "outputId": "317a5572-d2e4-4fc9-a9e3-a45000225468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar100_down_False.keras  cifar100_up_False.keras  main.py   __pycache__  util.py\n",
            "cifar100_down_True.keras   cifar100_up_True.keras   model.py  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the downloading in files is bugged for colab\n",
        "# so this command is separate from saving\n",
        "\n",
        "files.download(\"cifar100_down_False.keras\")\n",
        "files.download(\"cifar100_down_True.keras\")\n",
        "files.download(\"cifar100_up_False.keras\")\n",
        "files.download(\"cifar100_up_True.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YGJmaujFALW9",
        "outputId": "34f64d4f-24ad-463c-eb9d-e5917cece15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c7a3f03f-5556-4421-8fdf-2f135f7f46bb\", \"cifar100_down_False.keras\", 3361248)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ade5baad-86df-4c31-87fa-74eb8b4bbfae\", \"cifar100_down_True.keras\", 4460323)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e7234a8e-9676-4e78-b8b8-4f70a5126628\", \"cifar100_up_False.keras\", 8048719)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e4a45922-b772-4306-9048-72506097d4ce\", \"cifar100_up_True.keras\", 10710294)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}