{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile util.py\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "def exportModel(history, polarity, amsgrad, model, bias, learningRate):\n",
        "  \"\"\"\n",
        "  this function allows us to save the model in its final state\n",
        "  for later experimentation, use, and reproducability storage\n",
        "\n",
        "  NOTE: this function is designed for google colab\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  fileName=\"cifar100_\"+str(polarity)+\"_\"+str(amsgrad)+\"_B\"+str(bias)+\"_LR\"+str(learningRate)+\".keras\"\n",
        "  print(fileName)\n",
        "  model.save(fileName)\n",
        "  #files.download(fileName)\n",
        "\n",
        "\n",
        "def getData(reproSeed=1):\n",
        "  \"\"\"\n",
        "  this function not only grabs the data from the source\n",
        "  but also does a true 3 way split\n",
        "  as a 2 way split is only performed by default\n",
        "  which does not provide validation data\n",
        "\n",
        "  this function also prepares the data in a way\n",
        "  that works well with our model setup\n",
        "  \"\"\"\n",
        "\n",
        "  # first split, from obtaining the data\n",
        "  (trainValImgs, trainValLabels),(testImgs, testLabels)= datasets.cifar100.load_data( )\n",
        "\n",
        "  # normalize the values because 255 format\n",
        "  # makes things difficult\n",
        "  trainValImgs = trainValImgs/255\n",
        "  testImgs = testImgs/255\n",
        "\n",
        "  #flatten to ensure compatable with later functions\n",
        "  trainValLabels = trainValLabels.ravel()\n",
        "  testLabels = testLabels.ravel()\n",
        "\n",
        "\n",
        "  # second split is needed to run testing\n",
        "  trainImgs, valImgs, trainLabels, valLabels = train_test_split(trainValImgs,\n",
        "                                                              trainValLabels,\n",
        "                                                              test_size=0.25,\n",
        "                                                              random_state=reproSeed)\n",
        "\n",
        "  return trainImgs, valImgs, trainLabels, valLabels, testImgs, testLabels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUFKHQIVvcP1",
        "outputId": "5bb05259-35f5-4f40-d411-7031da44ec26"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing util.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqvD5CYRt_jY",
        "outputId": "b5dd4ee3-bd35-4376-8a1b-a1ab868c34a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "def modelMaker(amsgrad= False, polarity = \"up\", bias=False, learningRate=0.001):\n",
        "  \"\"\"\n",
        "  this function creates and compiles a model\n",
        "\n",
        "  there are two settings for the architecture:\n",
        "    'up'   : the convolutional layers build up in filter count\n",
        "    'down' : the convolutional layers build down on filter count\n",
        "    (all kernels are the same size)\n",
        "\n",
        "  there are two settings for hyperparamters\n",
        "    'True' : ams grad is on\n",
        "    'False': ams grad is off\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  match polarity:\n",
        "    case \"up\":\n",
        "      model = models.Sequential([\n",
        "        layers.Input(shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        #layers.Conv2D(32, 3, strides=2, padding='same', use_bias=False),\n",
        "\n",
        "        layers.Conv2D(32, 3, padding='same', use_bias=bias), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(64, 3, padding='same', use_bias=bias), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(128, 3, padding='same', use_bias=bias), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "        layers.Flatten(),\n",
        "\n",
        "\n",
        "        layers.Dense(256, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(128, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(100, activation=\"softmax\")\n",
        "      ])\n",
        "      adamm=Adam(amsgrad=amsgrad, learning_rate=learningRate)\n",
        "      model.compile(optimizer=adamm,\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "      return model\n",
        "\n",
        "\n",
        "    case \"down\":\n",
        "      model = models.Sequential([\n",
        "        layers.Input(shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        #layers.Conv2D(32, 3, strides=2, padding='same', use_bias=False),\n",
        "\n",
        "        layers.Conv2D(128, 3, padding='same', use_bias=bias), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(64, 3, padding='same', use_bias=bias), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(32, 3, padding='same', use_bias=bias), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "        layers.Flatten(),\n",
        "\n",
        "\n",
        "        layers.Dense(256, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(128, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(100, activation=\"softmax\")\n",
        "      ])\n",
        "      adamm=Adam(amsgrad=amsgrad, learning_rate=learningRate)\n",
        "      model.compile(optimizer=adamm,\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "      return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "\n",
        "from util import *\n",
        "from model import *\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mainrun(polarity, amsgrad, bias,learningRate):\n",
        "  \"\"\"\n",
        "  this function is the main run for setting up\n",
        "  fitting, testing, and exporting our model\n",
        "\n",
        "  there are some manipulatable settings\n",
        "  but nothing that should be changed between tests\n",
        "  \"\"\"\n",
        "  # seed for reproducability\n",
        "  reproSeed=1\n",
        "  # max epochs\n",
        "  epoccs=100#20#00\n",
        "  # early stopping, does not always activate\n",
        "  # due to other regularizers at play\n",
        "  callback = callbacks.EarlyStopping(monitor='loss',\n",
        "                                                patience=5,\n",
        "                                                restore_best_weights=True)\n",
        "\n",
        "  # get cifar100 fine data with full 3 way split\n",
        "  trainImgs, valImgs, trainLabels, valLabels, testImgs, testLabels = getData(reproSeed=reproSeed)\n",
        "\n",
        "  # generate the model with architecture based on up or down\n",
        "  # and amsgrad on or off\n",
        "  model = modelMaker(amsgrad=amsgrad , polarity=polarity, bias=bias,learningRate=learningRate)\n",
        "\n",
        "  # show relavant information about the model\n",
        "  print(\"polarity:\", polarity,\"   amsgrad:\",  amsgrad)\n",
        "  model.summary()\n",
        "\n",
        "  # fit the model\n",
        "  history = model.fit(\n",
        "    trainImgs, trainLabels, epochs=epoccs, validation_data=(valImgs, valLabels),\n",
        "    callbacks=[callback], batch_size=50\n",
        "  )\n",
        "\n",
        "  # download the model so you can use it later\n",
        "  exportModel(history=history, polarity=polarity, amsgrad=amsgrad, model=model, bias=bias, learningRate=learningRate)\n",
        "\n",
        "  # placeholder until we get resampled CI testacc\n",
        "  testLoss, testAcc = model.evaluate(testImgs, testLabels)\n",
        "  print(f\"Test Accuracy: {testAcc*100:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  \"\"\"\n",
        "  each of these function calls is a new test\n",
        "  we need four total\n",
        "  (two architectures two hyperparameters)\n",
        "  more can be added, and individual ones can\n",
        "  be commed out\n",
        "  since these models take a long time to train\n",
        "\n",
        "  This setup helps maintain that we change\n",
        "  what we are interested in for the experiment\n",
        "  and hold all else constant\n",
        "  \"\"\"\n",
        "\n",
        "  #mainrun(polarity=\"up\", amsgrad=False,bias=False,learningRate=0.001)\n",
        "  #mainrun(polarity=\"up\", amsgrad=True, bias=False,learningRate=0.001)\n",
        "  #mainrun(polarity=\"down\", amsgrad=False,bias=False,learningRate=0.001)\n",
        "  #mainrun(polarity=\"down\", amsgrad=True,bias=False,learningRate=0.001)\n",
        "\n",
        "  #mainrun(polarity=\"up\", amsgrad=False,bias=True,learningRate=0.001)\n",
        "  #mainrun(polarity=\"up\", amsgrad=True, bias=True,learningRate=0.001)\n",
        "  #mainrun(polarity=\"down\", amsgrad=False,bias=True,learningRate=0.001)\n",
        "  #mainrun(polarity=\"down\", amsgrad=True,bias=True,learningRate=0.001)\n",
        "\n",
        "  #mainrun(polarity=\"up\", amsgrad=False,bias=False,learningRate=0.0001)\n",
        "  #mainrun(polarity=\"up\", amsgrad=True, bias=False,learningRate=0.0001)\n",
        "  #mainrun(polarity=\"down\", amsgrad=False,bias=False,learningRate=0.0001)\n",
        "  #mainrun(polarity=\"down\", amsgrad=True,bias=False,learningRate=0.0001)\n",
        "\n",
        "  mainrun(polarity=\"up\", amsgrad=False,bias=True,learningRate=0.0001)\n",
        "  mainrun(polarity=\"up\", amsgrad=True, bias=True,learningRate=0.0001)\n",
        "  mainrun(polarity=\"down\", amsgrad=False,bias=True,learningRate=0.0001)\n",
        "  mainrun(polarity=\"down\", amsgrad=True,bias=True,learningRate=0.0001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UfILMXtvDsc",
        "outputId": "68b1e9fb-89a6-49b1-f704-969f22422577"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPcJDqOq2ILS",
        "outputId": "ee23ae22-dc6b-4562-fb20-fa21bf43560b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-10 19:04:05.507189: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:95] Opening library: /usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2\n",
            "2024-07-10 19:04:05.507366: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:119] Libtpu path is: libtpu.so\n",
            "2024-07-10 19:04:05.560845: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n",
            "2024-07-10 19:04:22.290475: I external/local_xla/xla/service/service.cc:168] XLA service 0x5be418c57590 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\n",
            "2024-07-10 19:04:22.290544: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): TPU, 2a886c8\n",
            "2024-07-10 19:04:22.290557: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): TPU, 2a886c8\n",
            "2024-07-10 19:04:22.290567: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (2): TPU, 2a886c8\n",
            "2024-07-10 19:04:22.290577: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (3): TPU, 2a886c8\n",
            "2024-07-10 19:04:22.290586: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (4): TPU, 2a886c8\n",
            "2024-07-10 19:04:22.290595: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (5): TPU, 2a886c8\n",
            "2024-07-10 19:04:22.290604: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (6): TPU, 2a886c8\n",
            "2024-07-10 19:04:22.290613: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (7): TPU, 2a886c8\n",
            "2024-07-10 19:04:22.290756: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.290812: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.290866: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.290969: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.291047: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.291214: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.291295: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.291442: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.291502: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.291670: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.291828: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.291927: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.291988: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.292057: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.292159: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.292316: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.292416: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.292467: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.292552: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.292661: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.292835: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.292893: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.292987: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.293064: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.293161: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.293344: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.293408: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.293478: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.293570: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.293643: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.293838: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.293921: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.294027: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.294100: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.294157: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.294330: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.294405: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.294472: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.294589: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-10 19:04:22.294671: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "polarity: up    amsgrad: False\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (Batch  (None, 32, 32, 3)         12        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664496 (2.53 MB)\n",
            "Trainable params: 664042 (2.53 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 29s 36ms/step - loss: 9.0629 - accuracy: 0.0702 - val_loss: 7.4014 - val_accuracy: 0.1301\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 6.4011 - accuracy: 0.1583 - val_loss: 5.6862 - val_accuracy: 0.1776\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 5.0983 - accuracy: 0.2112 - val_loss: 4.7916 - val_accuracy: 0.2170\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 4.3722 - accuracy: 0.2547 - val_loss: 4.2401 - val_accuracy: 0.2490\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 3.9189 - accuracy: 0.2878 - val_loss: 3.8949 - val_accuracy: 0.2763\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 3.6032 - accuracy: 0.3206 - val_loss: 3.6654 - val_accuracy: 0.2954\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 3.3717 - accuracy: 0.3477 - val_loss: 3.5214 - val_accuracy: 0.3097\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 3.1975 - accuracy: 0.3671 - val_loss: 3.2910 - val_accuracy: 0.3374\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 3.0625 - accuracy: 0.3844 - val_loss: 3.1902 - val_accuracy: 0.3512\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.9550 - accuracy: 0.4007 - val_loss: 3.1796 - val_accuracy: 0.3463\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.8668 - accuracy: 0.4128 - val_loss: 3.1016 - val_accuracy: 0.3636\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.7830 - accuracy: 0.4248 - val_loss: 2.9970 - val_accuracy: 0.3825\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.7198 - accuracy: 0.4372 - val_loss: 2.9529 - val_accuracy: 0.3847\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.6641 - accuracy: 0.4494 - val_loss: 2.9141 - val_accuracy: 0.3957\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.6007 - accuracy: 0.4583 - val_loss: 2.8036 - val_accuracy: 0.4086\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.5622 - accuracy: 0.4648 - val_loss: 2.7934 - val_accuracy: 0.4148\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.5129 - accuracy: 0.4775 - val_loss: 2.8497 - val_accuracy: 0.4054\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.4777 - accuracy: 0.4850 - val_loss: 2.7416 - val_accuracy: 0.4285\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.4387 - accuracy: 0.4925 - val_loss: 2.7726 - val_accuracy: 0.4182\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3984 - accuracy: 0.5010 - val_loss: 2.6980 - val_accuracy: 0.4370\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3743 - accuracy: 0.5067 - val_loss: 2.7238 - val_accuracy: 0.4275\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.3431 - accuracy: 0.5099 - val_loss: 2.6705 - val_accuracy: 0.4394\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3094 - accuracy: 0.5205 - val_loss: 2.6397 - val_accuracy: 0.4465\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2793 - accuracy: 0.5286 - val_loss: 2.6554 - val_accuracy: 0.4480\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2560 - accuracy: 0.5337 - val_loss: 2.6115 - val_accuracy: 0.4556\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.2325 - accuracy: 0.5344 - val_loss: 2.6189 - val_accuracy: 0.4549\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.1990 - accuracy: 0.5470 - val_loss: 2.5738 - val_accuracy: 0.4617\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1825 - accuracy: 0.5477 - val_loss: 2.6340 - val_accuracy: 0.4494\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1562 - accuracy: 0.5564 - val_loss: 2.5643 - val_accuracy: 0.4623\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1366 - accuracy: 0.5608 - val_loss: 2.5448 - val_accuracy: 0.4699\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1088 - accuracy: 0.5665 - val_loss: 2.5404 - val_accuracy: 0.4740\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.0864 - accuracy: 0.5708 - val_loss: 2.5614 - val_accuracy: 0.4699\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.0657 - accuracy: 0.5825 - val_loss: 2.5204 - val_accuracy: 0.4778\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.0525 - accuracy: 0.5837 - val_loss: 2.5366 - val_accuracy: 0.4778\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.0291 - accuracy: 0.5881 - val_loss: 2.5371 - val_accuracy: 0.4766\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.0108 - accuracy: 0.5937 - val_loss: 2.5266 - val_accuracy: 0.4810\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.9971 - accuracy: 0.5978 - val_loss: 2.5143 - val_accuracy: 0.4841\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.9794 - accuracy: 0.6022 - val_loss: 2.5185 - val_accuracy: 0.4830\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.9587 - accuracy: 0.6069 - val_loss: 2.5354 - val_accuracy: 0.4828\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.9441 - accuracy: 0.6102 - val_loss: 2.5071 - val_accuracy: 0.4888\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.9205 - accuracy: 0.6193 - val_loss: 2.5004 - val_accuracy: 0.4924\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.9061 - accuracy: 0.6218 - val_loss: 2.5222 - val_accuracy: 0.4907\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.8909 - accuracy: 0.6255 - val_loss: 2.4818 - val_accuracy: 0.4942\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.8818 - accuracy: 0.6284 - val_loss: 2.4850 - val_accuracy: 0.4952\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.8658 - accuracy: 0.6313 - val_loss: 2.5052 - val_accuracy: 0.4945\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.8447 - accuracy: 0.6395 - val_loss: 2.4867 - val_accuracy: 0.4988\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.8364 - accuracy: 0.6415 - val_loss: 2.4795 - val_accuracy: 0.4999\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.8169 - accuracy: 0.6473 - val_loss: 2.4938 - val_accuracy: 0.4931\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.8083 - accuracy: 0.6489 - val_loss: 2.4996 - val_accuracy: 0.4986\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.7936 - accuracy: 0.6534 - val_loss: 2.5044 - val_accuracy: 0.4964\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.7742 - accuracy: 0.6602 - val_loss: 2.4812 - val_accuracy: 0.5053\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.7700 - accuracy: 0.6614 - val_loss: 2.4609 - val_accuracy: 0.5070\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.7507 - accuracy: 0.6687 - val_loss: 2.5134 - val_accuracy: 0.4947\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.7477 - accuracy: 0.6676 - val_loss: 2.4961 - val_accuracy: 0.5040\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.7256 - accuracy: 0.6720 - val_loss: 2.5080 - val_accuracy: 0.4990\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.7106 - accuracy: 0.6796 - val_loss: 2.5086 - val_accuracy: 0.5027\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.7042 - accuracy: 0.6784 - val_loss: 2.4994 - val_accuracy: 0.5037\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6897 - accuracy: 0.6819 - val_loss: 2.4872 - val_accuracy: 0.5065\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6767 - accuracy: 0.6881 - val_loss: 2.5531 - val_accuracy: 0.4961\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6718 - accuracy: 0.6901 - val_loss: 2.5147 - val_accuracy: 0.5022\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6553 - accuracy: 0.6920 - val_loss: 2.5100 - val_accuracy: 0.5070\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.6442 - accuracy: 0.6961 - val_loss: 2.4960 - val_accuracy: 0.5090\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6389 - accuracy: 0.6970 - val_loss: 2.5193 - val_accuracy: 0.5063\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6254 - accuracy: 0.7021 - val_loss: 2.5029 - val_accuracy: 0.5089\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.6119 - accuracy: 0.7032 - val_loss: 2.5062 - val_accuracy: 0.5074\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.6029 - accuracy: 0.7073 - val_loss: 2.5054 - val_accuracy: 0.5057\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5959 - accuracy: 0.7103 - val_loss: 2.5155 - val_accuracy: 0.5093\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5841 - accuracy: 0.7147 - val_loss: 2.5314 - val_accuracy: 0.5030\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.5743 - accuracy: 0.7154 - val_loss: 2.5042 - val_accuracy: 0.5102\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5658 - accuracy: 0.7184 - val_loss: 2.5171 - val_accuracy: 0.5047\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.5581 - accuracy: 0.7186 - val_loss: 2.5192 - val_accuracy: 0.5106\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5403 - accuracy: 0.7268 - val_loss: 2.5244 - val_accuracy: 0.5103\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5372 - accuracy: 0.7253 - val_loss: 2.5326 - val_accuracy: 0.5089\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.5272 - accuracy: 0.7295 - val_loss: 2.5355 - val_accuracy: 0.5058\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5164 - accuracy: 0.7311 - val_loss: 2.5102 - val_accuracy: 0.5137\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.5095 - accuracy: 0.7358 - val_loss: 2.5319 - val_accuracy: 0.5084\n",
            "Epoch 77/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4935 - accuracy: 0.7404 - val_loss: 2.5410 - val_accuracy: 0.5114\n",
            "Epoch 78/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4926 - accuracy: 0.7388 - val_loss: 2.5381 - val_accuracy: 0.5121\n",
            "Epoch 79/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4885 - accuracy: 0.7394 - val_loss: 2.5723 - val_accuracy: 0.5095\n",
            "Epoch 80/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4846 - accuracy: 0.7413 - val_loss: 2.5790 - val_accuracy: 0.5023\n",
            "Epoch 81/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4623 - accuracy: 0.7482 - val_loss: 2.5330 - val_accuracy: 0.5122\n",
            "Epoch 82/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4599 - accuracy: 0.7497 - val_loss: 2.5978 - val_accuracy: 0.5029\n",
            "Epoch 83/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4500 - accuracy: 0.7506 - val_loss: 2.5486 - val_accuracy: 0.5102\n",
            "Epoch 84/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4421 - accuracy: 0.7554 - val_loss: 2.5424 - val_accuracy: 0.5120\n",
            "Epoch 85/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4396 - accuracy: 0.7552 - val_loss: 2.5340 - val_accuracy: 0.5105\n",
            "Epoch 86/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.4255 - accuracy: 0.7601 - val_loss: 2.5599 - val_accuracy: 0.5095\n",
            "Epoch 87/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4245 - accuracy: 0.7586 - val_loss: 2.5666 - val_accuracy: 0.5132\n",
            "Epoch 88/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4150 - accuracy: 0.7626 - val_loss: 2.5901 - val_accuracy: 0.5023\n",
            "Epoch 89/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4067 - accuracy: 0.7618 - val_loss: 2.5408 - val_accuracy: 0.5115\n",
            "Epoch 90/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4033 - accuracy: 0.7657 - val_loss: 2.5880 - val_accuracy: 0.5127\n",
            "Epoch 91/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.3970 - accuracy: 0.7643 - val_loss: 2.5415 - val_accuracy: 0.5160\n",
            "Epoch 92/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.3847 - accuracy: 0.7707 - val_loss: 2.5669 - val_accuracy: 0.5129\n",
            "Epoch 93/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.3819 - accuracy: 0.7721 - val_loss: 2.5817 - val_accuracy: 0.5082\n",
            "Epoch 94/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.3700 - accuracy: 0.7734 - val_loss: 2.5634 - val_accuracy: 0.5129\n",
            "Epoch 95/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.3722 - accuracy: 0.7702 - val_loss: 2.5847 - val_accuracy: 0.5113\n",
            "Epoch 96/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.3613 - accuracy: 0.7737 - val_loss: 2.5898 - val_accuracy: 0.5112\n",
            "Epoch 97/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.3544 - accuracy: 0.7772 - val_loss: 2.5810 - val_accuracy: 0.5150\n",
            "Epoch 98/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.3446 - accuracy: 0.7805 - val_loss: 2.5824 - val_accuracy: 0.5087\n",
            "Epoch 99/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.3378 - accuracy: 0.7806 - val_loss: 2.5928 - val_accuracy: 0.5125\n",
            "Epoch 100/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.3325 - accuracy: 0.7826 - val_loss: 2.5590 - val_accuracy: 0.5166\n",
            "cifar100_up_False_BTrue_LR0.0001.keras\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 2.5466 - accuracy: 0.5163\n",
            "Test Accuracy: 51.63%\n",
            "polarity: up    amsgrad: True\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_4 (Bat  (None, 32, 32, 3)         12        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664496 (2.53 MB)\n",
            "Trainable params: 664042 (2.53 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 28s 35ms/step - loss: 9.0155 - accuracy: 0.0694 - val_loss: 7.3560 - val_accuracy: 0.1155\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 6.3099 - accuracy: 0.1540 - val_loss: 5.6190 - val_accuracy: 0.1717\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 5.0374 - accuracy: 0.2092 - val_loss: 4.8136 - val_accuracy: 0.2019\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 4.3424 - accuracy: 0.2492 - val_loss: 4.3093 - val_accuracy: 0.2339\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 3.8969 - accuracy: 0.2837 - val_loss: 4.0152 - val_accuracy: 0.2511\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 3.5929 - accuracy: 0.3166 - val_loss: 3.7804 - val_accuracy: 0.2711\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 3.3710 - accuracy: 0.3411 - val_loss: 3.5622 - val_accuracy: 0.2902\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 3.2037 - accuracy: 0.3623 - val_loss: 3.3526 - val_accuracy: 0.3179\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 3.0697 - accuracy: 0.3833 - val_loss: 3.2350 - val_accuracy: 0.3354\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.9670 - accuracy: 0.3955 - val_loss: 3.1812 - val_accuracy: 0.3399\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.8740 - accuracy: 0.4115 - val_loss: 3.0844 - val_accuracy: 0.3667\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.7994 - accuracy: 0.4216 - val_loss: 3.1245 - val_accuracy: 0.3514\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.7351 - accuracy: 0.4338 - val_loss: 2.9852 - val_accuracy: 0.3787\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.6754 - accuracy: 0.4439 - val_loss: 2.8993 - val_accuracy: 0.3885\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.6284 - accuracy: 0.4538 - val_loss: 2.9504 - val_accuracy: 0.3855\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.5846 - accuracy: 0.4612 - val_loss: 2.8911 - val_accuracy: 0.3958\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.5407 - accuracy: 0.4693 - val_loss: 2.8213 - val_accuracy: 0.4072\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.4962 - accuracy: 0.4798 - val_loss: 2.7350 - val_accuracy: 0.4245\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.4596 - accuracy: 0.4887 - val_loss: 2.7604 - val_accuracy: 0.4172\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.4270 - accuracy: 0.4936 - val_loss: 2.7543 - val_accuracy: 0.4226\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3937 - accuracy: 0.5031 - val_loss: 2.7433 - val_accuracy: 0.4237\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3654 - accuracy: 0.5068 - val_loss: 2.6764 - val_accuracy: 0.4385\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.3364 - accuracy: 0.5142 - val_loss: 2.6579 - val_accuracy: 0.4442\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.3045 - accuracy: 0.5197 - val_loss: 2.6260 - val_accuracy: 0.4504\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2718 - accuracy: 0.5283 - val_loss: 2.6164 - val_accuracy: 0.4498\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2564 - accuracy: 0.5330 - val_loss: 2.6154 - val_accuracy: 0.4563\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2303 - accuracy: 0.5370 - val_loss: 2.5889 - val_accuracy: 0.4582\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.2038 - accuracy: 0.5437 - val_loss: 2.6199 - val_accuracy: 0.4574\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1867 - accuracy: 0.5464 - val_loss: 2.5845 - val_accuracy: 0.4598\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1673 - accuracy: 0.5544 - val_loss: 2.5475 - val_accuracy: 0.4706\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1442 - accuracy: 0.5596 - val_loss: 2.5516 - val_accuracy: 0.4697\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.1225 - accuracy: 0.5656 - val_loss: 2.5560 - val_accuracy: 0.4688\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.0981 - accuracy: 0.5735 - val_loss: 2.5604 - val_accuracy: 0.4694\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.0799 - accuracy: 0.5754 - val_loss: 2.5558 - val_accuracy: 0.4699\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.0614 - accuracy: 0.5797 - val_loss: 2.5017 - val_accuracy: 0.4787\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.0449 - accuracy: 0.5812 - val_loss: 2.5485 - val_accuracy: 0.4710\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 2.0258 - accuracy: 0.5880 - val_loss: 2.5435 - val_accuracy: 0.4774\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 2.0179 - accuracy: 0.5909 - val_loss: 2.5097 - val_accuracy: 0.4784\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.9980 - accuracy: 0.5967 - val_loss: 2.5064 - val_accuracy: 0.4842\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.9713 - accuracy: 0.6057 - val_loss: 2.4673 - val_accuracy: 0.4891\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.9641 - accuracy: 0.6077 - val_loss: 2.4934 - val_accuracy: 0.4870\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.9502 - accuracy: 0.6081 - val_loss: 2.4858 - val_accuracy: 0.4858\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.9335 - accuracy: 0.6175 - val_loss: 2.5240 - val_accuracy: 0.4815\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.9125 - accuracy: 0.6223 - val_loss: 2.4863 - val_accuracy: 0.4901\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.8993 - accuracy: 0.6255 - val_loss: 2.4986 - val_accuracy: 0.4905\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.8892 - accuracy: 0.6286 - val_loss: 2.4874 - val_accuracy: 0.4945\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.8793 - accuracy: 0.6296 - val_loss: 2.4364 - val_accuracy: 0.5003\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.8597 - accuracy: 0.6335 - val_loss: 2.5325 - val_accuracy: 0.4898\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.8473 - accuracy: 0.6377 - val_loss: 2.4814 - val_accuracy: 0.4950\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.8312 - accuracy: 0.6457 - val_loss: 2.5209 - val_accuracy: 0.4863\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.8225 - accuracy: 0.6473 - val_loss: 2.4594 - val_accuracy: 0.5060\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.8083 - accuracy: 0.6511 - val_loss: 2.4911 - val_accuracy: 0.4977\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.7987 - accuracy: 0.6510 - val_loss: 2.5057 - val_accuracy: 0.4987\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.7800 - accuracy: 0.6567 - val_loss: 2.4688 - val_accuracy: 0.5033\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.7738 - accuracy: 0.6593 - val_loss: 2.4957 - val_accuracy: 0.4982\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.7637 - accuracy: 0.6651 - val_loss: 2.5140 - val_accuracy: 0.4974\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.7526 - accuracy: 0.6654 - val_loss: 2.4798 - val_accuracy: 0.5076\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.7351 - accuracy: 0.6717 - val_loss: 2.4691 - val_accuracy: 0.5066\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.7285 - accuracy: 0.6723 - val_loss: 2.4820 - val_accuracy: 0.5034\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.7118 - accuracy: 0.6794 - val_loss: 2.4795 - val_accuracy: 0.5057\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.7029 - accuracy: 0.6815 - val_loss: 2.4814 - val_accuracy: 0.5065\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6987 - accuracy: 0.6805 - val_loss: 2.4665 - val_accuracy: 0.5076\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6828 - accuracy: 0.6871 - val_loss: 2.4718 - val_accuracy: 0.5087\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6805 - accuracy: 0.6877 - val_loss: 2.5111 - val_accuracy: 0.5017\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6587 - accuracy: 0.6923 - val_loss: 2.4717 - val_accuracy: 0.5090\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6509 - accuracy: 0.6946 - val_loss: 2.4618 - val_accuracy: 0.5107\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.6387 - accuracy: 0.6985 - val_loss: 2.4847 - val_accuracy: 0.5102\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6341 - accuracy: 0.7006 - val_loss: 2.4818 - val_accuracy: 0.5117\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.6282 - accuracy: 0.7004 - val_loss: 2.4855 - val_accuracy: 0.5123\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.6175 - accuracy: 0.7043 - val_loss: 2.5188 - val_accuracy: 0.5071\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.6012 - accuracy: 0.7108 - val_loss: 2.4887 - val_accuracy: 0.5106\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.6030 - accuracy: 0.7101 - val_loss: 2.4889 - val_accuracy: 0.5108\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5974 - accuracy: 0.7097 - val_loss: 2.4937 - val_accuracy: 0.5112\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5816 - accuracy: 0.7154 - val_loss: 2.5127 - val_accuracy: 0.5113\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5765 - accuracy: 0.7152 - val_loss: 2.5267 - val_accuracy: 0.5073\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.5627 - accuracy: 0.7223 - val_loss: 2.4755 - val_accuracy: 0.5155\n",
            "Epoch 77/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5552 - accuracy: 0.7241 - val_loss: 2.5013 - val_accuracy: 0.5127\n",
            "Epoch 78/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5463 - accuracy: 0.7274 - val_loss: 2.4989 - val_accuracy: 0.5164\n",
            "Epoch 79/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5429 - accuracy: 0.7283 - val_loss: 2.5055 - val_accuracy: 0.5128\n",
            "Epoch 80/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5315 - accuracy: 0.7290 - val_loss: 2.5097 - val_accuracy: 0.5155\n",
            "Epoch 81/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5243 - accuracy: 0.7330 - val_loss: 2.4856 - val_accuracy: 0.5158\n",
            "Epoch 82/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5190 - accuracy: 0.7354 - val_loss: 2.5160 - val_accuracy: 0.5142\n",
            "Epoch 83/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.5105 - accuracy: 0.7382 - val_loss: 2.5231 - val_accuracy: 0.5122\n",
            "Epoch 84/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.5050 - accuracy: 0.7379 - val_loss: 2.5316 - val_accuracy: 0.5100\n",
            "Epoch 85/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4939 - accuracy: 0.7431 - val_loss: 2.5006 - val_accuracy: 0.5113\n",
            "Epoch 86/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.4926 - accuracy: 0.7420 - val_loss: 2.4949 - val_accuracy: 0.5155\n",
            "Epoch 87/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4793 - accuracy: 0.7458 - val_loss: 2.5299 - val_accuracy: 0.5130\n",
            "Epoch 88/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4739 - accuracy: 0.7453 - val_loss: 2.4843 - val_accuracy: 0.5246\n",
            "Epoch 89/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4623 - accuracy: 0.7503 - val_loss: 2.5054 - val_accuracy: 0.5158\n",
            "Epoch 90/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.4598 - accuracy: 0.7490 - val_loss: 2.4799 - val_accuracy: 0.5209\n",
            "Epoch 91/100\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 1.4544 - accuracy: 0.7535 - val_loss: 2.5070 - val_accuracy: 0.5157\n",
            "Epoch 92/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4465 - accuracy: 0.7553 - val_loss: 2.5061 - val_accuracy: 0.5195\n",
            "Epoch 93/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4469 - accuracy: 0.7514 - val_loss: 2.5490 - val_accuracy: 0.5096\n",
            "Epoch 94/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4362 - accuracy: 0.7586 - val_loss: 2.5343 - val_accuracy: 0.5132\n",
            "Epoch 95/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.4161 - accuracy: 0.7636 - val_loss: 2.5476 - val_accuracy: 0.5131\n",
            "Epoch 96/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.4244 - accuracy: 0.7599 - val_loss: 2.5289 - val_accuracy: 0.5178\n",
            "Epoch 97/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4187 - accuracy: 0.7630 - val_loss: 2.5416 - val_accuracy: 0.5154\n",
            "Epoch 98/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.4071 - accuracy: 0.7668 - val_loss: 2.5468 - val_accuracy: 0.5154\n",
            "Epoch 99/100\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 1.4026 - accuracy: 0.7701 - val_loss: 2.5247 - val_accuracy: 0.5207\n",
            "Epoch 100/100\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 1.3956 - accuracy: 0.7690 - val_loss: 2.5312 - val_accuracy: 0.5149\n",
            "cifar100_up_True_BTrue_LR0.0001.keras\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 2.4935 - accuracy: 0.5221\n",
            "Test Accuracy: 52.21%\n",
            "polarity: down    amsgrad: False\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_8 (Bat  (None, 32, 32, 3)         12        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 128)       3584      \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 32, 32, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 16, 16, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 8, 8, 32)          18464     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 8, 8, 32)          128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 4, 4, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 4, 4, 32)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273872 (1.04 MB)\n",
            "Trainable params: 273418 (1.04 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 44s 56ms/step - loss: 8.3756 - accuracy: 0.0509 - val_loss: 7.1189 - val_accuracy: 0.0998\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 6.2295 - accuracy: 0.1222 - val_loss: 5.5927 - val_accuracy: 0.1504\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 5.0714 - accuracy: 0.1710 - val_loss: 4.7959 - val_accuracy: 0.1782\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 4.4286 - accuracy: 0.2078 - val_loss: 4.2720 - val_accuracy: 0.2225\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 4.0429 - accuracy: 0.2332 - val_loss: 3.9747 - val_accuracy: 0.2321\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 3.7764 - accuracy: 0.2583 - val_loss: 3.7505 - val_accuracy: 0.2508\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 3.5871 - accuracy: 0.2768 - val_loss: 3.5307 - val_accuracy: 0.2829\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 3.4297 - accuracy: 0.2940 - val_loss: 3.3730 - val_accuracy: 0.2982\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 3.3132 - accuracy: 0.3070 - val_loss: 3.2467 - val_accuracy: 0.3114\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 3.2060 - accuracy: 0.3241 - val_loss: 3.1575 - val_accuracy: 0.3291\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 3.1235 - accuracy: 0.3320 - val_loss: 3.0986 - val_accuracy: 0.3310\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 3.0461 - accuracy: 0.3449 - val_loss: 3.0223 - val_accuracy: 0.3398\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.9910 - accuracy: 0.3518 - val_loss: 2.9561 - val_accuracy: 0.3545\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.9395 - accuracy: 0.3581 - val_loss: 2.9184 - val_accuracy: 0.3610\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.8857 - accuracy: 0.3686 - val_loss: 2.8411 - val_accuracy: 0.3726\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.8563 - accuracy: 0.3748 - val_loss: 2.8087 - val_accuracy: 0.3795\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.8068 - accuracy: 0.3807 - val_loss: 2.7872 - val_accuracy: 0.3842\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.7708 - accuracy: 0.3873 - val_loss: 2.7497 - val_accuracy: 0.3904\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.7336 - accuracy: 0.3943 - val_loss: 2.7064 - val_accuracy: 0.3967\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.7123 - accuracy: 0.3936 - val_loss: 2.7067 - val_accuracy: 0.3901\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.6863 - accuracy: 0.3991 - val_loss: 2.6464 - val_accuracy: 0.4055\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.6544 - accuracy: 0.4070 - val_loss: 2.6631 - val_accuracy: 0.3978\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.6284 - accuracy: 0.4104 - val_loss: 2.6175 - val_accuracy: 0.4102\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.6054 - accuracy: 0.4145 - val_loss: 2.6199 - val_accuracy: 0.4099\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.5878 - accuracy: 0.4179 - val_loss: 2.6218 - val_accuracy: 0.4106\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.5691 - accuracy: 0.4190 - val_loss: 2.5578 - val_accuracy: 0.4186\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.5375 - accuracy: 0.4257 - val_loss: 2.5544 - val_accuracy: 0.4202\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.5247 - accuracy: 0.4288 - val_loss: 2.5219 - val_accuracy: 0.4240\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.5165 - accuracy: 0.4303 - val_loss: 2.5243 - val_accuracy: 0.4240\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.4834 - accuracy: 0.4380 - val_loss: 2.5114 - val_accuracy: 0.4221\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4736 - accuracy: 0.4375 - val_loss: 2.4958 - val_accuracy: 0.4310\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4568 - accuracy: 0.4420 - val_loss: 2.4883 - val_accuracy: 0.4327\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4363 - accuracy: 0.4441 - val_loss: 2.4809 - val_accuracy: 0.4378\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4250 - accuracy: 0.4489 - val_loss: 2.4702 - val_accuracy: 0.4392\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4085 - accuracy: 0.4496 - val_loss: 2.4540 - val_accuracy: 0.4394\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.3900 - accuracy: 0.4551 - val_loss: 2.4531 - val_accuracy: 0.4424\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 2.3804 - accuracy: 0.4576 - val_loss: 2.4097 - val_accuracy: 0.4502\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.3640 - accuracy: 0.4602 - val_loss: 2.4160 - val_accuracy: 0.4494\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.3524 - accuracy: 0.4634 - val_loss: 2.4321 - val_accuracy: 0.4468\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.3429 - accuracy: 0.4639 - val_loss: 2.3962 - val_accuracy: 0.4510\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.3267 - accuracy: 0.4697 - val_loss: 2.4016 - val_accuracy: 0.4546\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.3205 - accuracy: 0.4673 - val_loss: 2.3780 - val_accuracy: 0.4490\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.3119 - accuracy: 0.4721 - val_loss: 2.3872 - val_accuracy: 0.4497\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2930 - accuracy: 0.4731 - val_loss: 2.3886 - val_accuracy: 0.4518\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2799 - accuracy: 0.4787 - val_loss: 2.3657 - val_accuracy: 0.4551\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2675 - accuracy: 0.4782 - val_loss: 2.3503 - val_accuracy: 0.4618\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2591 - accuracy: 0.4815 - val_loss: 2.3693 - val_accuracy: 0.4598\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2541 - accuracy: 0.4829 - val_loss: 2.3458 - val_accuracy: 0.4598\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2438 - accuracy: 0.4826 - val_loss: 2.3149 - val_accuracy: 0.4677\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.2209 - accuracy: 0.4891 - val_loss: 2.3240 - val_accuracy: 0.4719\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2217 - accuracy: 0.4886 - val_loss: 2.2938 - val_accuracy: 0.4741\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2058 - accuracy: 0.4941 - val_loss: 2.3085 - val_accuracy: 0.4756\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.2030 - accuracy: 0.4950 - val_loss: 2.3076 - val_accuracy: 0.4718\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.1962 - accuracy: 0.4916 - val_loss: 2.3070 - val_accuracy: 0.4713\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1804 - accuracy: 0.4991 - val_loss: 2.2836 - val_accuracy: 0.4806\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1757 - accuracy: 0.5022 - val_loss: 2.2867 - val_accuracy: 0.4806\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.1632 - accuracy: 0.5013 - val_loss: 2.2772 - val_accuracy: 0.4819\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1650 - accuracy: 0.5030 - val_loss: 2.2686 - val_accuracy: 0.4800\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1412 - accuracy: 0.5084 - val_loss: 2.2748 - val_accuracy: 0.4785\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.1371 - accuracy: 0.5103 - val_loss: 2.2684 - val_accuracy: 0.4786\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1301 - accuracy: 0.5139 - val_loss: 2.2664 - val_accuracy: 0.4816\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.1243 - accuracy: 0.5121 - val_loss: 2.2625 - val_accuracy: 0.4816\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1137 - accuracy: 0.5152 - val_loss: 2.2757 - val_accuracy: 0.4790\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1100 - accuracy: 0.5167 - val_loss: 2.2414 - val_accuracy: 0.4853\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0962 - accuracy: 0.5209 - val_loss: 2.2451 - val_accuracy: 0.4876\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.0911 - accuracy: 0.5184 - val_loss: 2.2258 - val_accuracy: 0.4935\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0833 - accuracy: 0.5217 - val_loss: 2.2345 - val_accuracy: 0.4912\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.0792 - accuracy: 0.5239 - val_loss: 2.2269 - val_accuracy: 0.4959\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.0699 - accuracy: 0.5243 - val_loss: 2.2460 - val_accuracy: 0.4898\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0575 - accuracy: 0.5285 - val_loss: 2.2310 - val_accuracy: 0.4918\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.0451 - accuracy: 0.5303 - val_loss: 2.2085 - val_accuracy: 0.4964\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.0458 - accuracy: 0.5336 - val_loss: 2.2289 - val_accuracy: 0.4962\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.0432 - accuracy: 0.5313 - val_loss: 2.1864 - val_accuracy: 0.5026\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.0274 - accuracy: 0.5342 - val_loss: 2.2404 - val_accuracy: 0.4909\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0205 - accuracy: 0.5364 - val_loss: 2.2254 - val_accuracy: 0.4914\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0207 - accuracy: 0.5389 - val_loss: 2.2031 - val_accuracy: 0.4986\n",
            "Epoch 77/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.0199 - accuracy: 0.5358 - val_loss: 2.1990 - val_accuracy: 0.4991\n",
            "Epoch 78/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 1.9976 - accuracy: 0.5421 - val_loss: 2.2198 - val_accuracy: 0.4922\n",
            "Epoch 79/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0009 - accuracy: 0.5419 - val_loss: 2.2073 - val_accuracy: 0.4984\n",
            "Epoch 80/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 1.9895 - accuracy: 0.5451 - val_loss: 2.2020 - val_accuracy: 0.5009\n",
            "Epoch 81/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 1.9868 - accuracy: 0.5447 - val_loss: 2.1972 - val_accuracy: 0.5025\n",
            "Epoch 82/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.9786 - accuracy: 0.5449 - val_loss: 2.1861 - val_accuracy: 0.5047\n",
            "Epoch 83/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 1.9661 - accuracy: 0.5502 - val_loss: 2.1755 - val_accuracy: 0.5057\n",
            "Epoch 84/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 1.9680 - accuracy: 0.5483 - val_loss: 2.1916 - val_accuracy: 0.5012\n",
            "Epoch 85/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 1.9564 - accuracy: 0.5516 - val_loss: 2.1876 - val_accuracy: 0.5014\n",
            "Epoch 86/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 1.9560 - accuracy: 0.5546 - val_loss: 2.1717 - val_accuracy: 0.5058\n",
            "Epoch 87/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 1.9520 - accuracy: 0.5548 - val_loss: 2.1754 - val_accuracy: 0.5050\n",
            "Epoch 88/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.9450 - accuracy: 0.5567 - val_loss: 2.1607 - val_accuracy: 0.5082\n",
            "Epoch 89/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 1.9327 - accuracy: 0.5596 - val_loss: 2.1628 - val_accuracy: 0.5102\n",
            "Epoch 90/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 1.9265 - accuracy: 0.5607 - val_loss: 2.1904 - val_accuracy: 0.5015\n",
            "Epoch 91/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 1.9257 - accuracy: 0.5615 - val_loss: 2.1546 - val_accuracy: 0.5136\n",
            "Epoch 92/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 1.9194 - accuracy: 0.5628 - val_loss: 2.1787 - val_accuracy: 0.5043\n",
            "Epoch 93/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 1.9169 - accuracy: 0.5640 - val_loss: 2.1856 - val_accuracy: 0.5065\n",
            "Epoch 94/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 1.9021 - accuracy: 0.5682 - val_loss: 2.1647 - val_accuracy: 0.5092\n",
            "Epoch 95/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 1.8980 - accuracy: 0.5690 - val_loss: 2.1489 - val_accuracy: 0.5134\n",
            "Epoch 96/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.8935 - accuracy: 0.5690 - val_loss: 2.2034 - val_accuracy: 0.5010\n",
            "Epoch 97/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.8939 - accuracy: 0.5714 - val_loss: 2.1658 - val_accuracy: 0.5114\n",
            "Epoch 98/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 1.8867 - accuracy: 0.5659 - val_loss: 2.1700 - val_accuracy: 0.5076\n",
            "Epoch 99/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.8822 - accuracy: 0.5703 - val_loss: 2.1705 - val_accuracy: 0.5073\n",
            "Epoch 100/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.8721 - accuracy: 0.5749 - val_loss: 2.1667 - val_accuracy: 0.5122\n",
            "cifar100_down_False_BTrue_LR0.0001.keras\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.1427 - accuracy: 0.5134\n",
            "Test Accuracy: 51.34%\n",
            "polarity: down    amsgrad: True\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_12 (Ba  (None, 32, 32, 3)         12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 128)       3584      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 32, 32, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 16, 16, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 8, 8, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 32)          18464     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 8, 8, 32)          128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 4, 4, 32)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 4, 4, 32)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273872 (1.04 MB)\n",
            "Trainable params: 273418 (1.04 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 43s 55ms/step - loss: 8.4674 - accuracy: 0.0474 - val_loss: 7.2134 - val_accuracy: 0.1002\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 6.3280 - accuracy: 0.1230 - val_loss: 5.6545 - val_accuracy: 0.1640\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 5.1596 - accuracy: 0.1693 - val_loss: 4.8046 - val_accuracy: 0.1947\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 4.4962 - accuracy: 0.2066 - val_loss: 4.2698 - val_accuracy: 0.2294\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 4.0830 - accuracy: 0.2352 - val_loss: 3.9656 - val_accuracy: 0.2471\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 3.8086 - accuracy: 0.2588 - val_loss: 3.7042 - val_accuracy: 0.2762\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 3.5999 - accuracy: 0.2808 - val_loss: 3.5311 - val_accuracy: 0.2897\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 3.4450 - accuracy: 0.2950 - val_loss: 3.3963 - val_accuracy: 0.3030\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 3.3055 - accuracy: 0.3155 - val_loss: 3.2684 - val_accuracy: 0.3179\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 3.2114 - accuracy: 0.3292 - val_loss: 3.1540 - val_accuracy: 0.3300\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 3.1266 - accuracy: 0.3389 - val_loss: 3.1048 - val_accuracy: 0.3382\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 3.0583 - accuracy: 0.3454 - val_loss: 3.0172 - val_accuracy: 0.3505\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.9969 - accuracy: 0.3547 - val_loss: 2.9649 - val_accuracy: 0.3588\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.9435 - accuracy: 0.3618 - val_loss: 2.9187 - val_accuracy: 0.3658\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.8979 - accuracy: 0.3695 - val_loss: 2.8919 - val_accuracy: 0.3685\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.8607 - accuracy: 0.3751 - val_loss: 2.8400 - val_accuracy: 0.3758\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.8205 - accuracy: 0.3820 - val_loss: 2.7913 - val_accuracy: 0.3832\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.7886 - accuracy: 0.3869 - val_loss: 2.7930 - val_accuracy: 0.3857\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.7547 - accuracy: 0.3920 - val_loss: 2.7444 - val_accuracy: 0.3910\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.7328 - accuracy: 0.3943 - val_loss: 2.7148 - val_accuracy: 0.3962\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.7004 - accuracy: 0.4002 - val_loss: 2.7017 - val_accuracy: 0.3972\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.6714 - accuracy: 0.4036 - val_loss: 2.6675 - val_accuracy: 0.4037\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.6473 - accuracy: 0.4078 - val_loss: 2.6524 - val_accuracy: 0.4072\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.6283 - accuracy: 0.4098 - val_loss: 2.6064 - val_accuracy: 0.4147\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.6052 - accuracy: 0.4155 - val_loss: 2.6157 - val_accuracy: 0.4073\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.5848 - accuracy: 0.4207 - val_loss: 2.5671 - val_accuracy: 0.4229\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.5693 - accuracy: 0.4254 - val_loss: 2.5668 - val_accuracy: 0.4222\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.5561 - accuracy: 0.4233 - val_loss: 2.5397 - val_accuracy: 0.4270\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.5250 - accuracy: 0.4316 - val_loss: 2.5383 - val_accuracy: 0.4255\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.5131 - accuracy: 0.4341 - val_loss: 2.5542 - val_accuracy: 0.4230\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.4969 - accuracy: 0.4355 - val_loss: 2.5173 - val_accuracy: 0.4327\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.4836 - accuracy: 0.4381 - val_loss: 2.4836 - val_accuracy: 0.4401\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4585 - accuracy: 0.4446 - val_loss: 2.4830 - val_accuracy: 0.4386\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4553 - accuracy: 0.4433 - val_loss: 2.4768 - val_accuracy: 0.4400\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.4373 - accuracy: 0.4482 - val_loss: 2.4629 - val_accuracy: 0.4399\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4269 - accuracy: 0.4496 - val_loss: 2.4917 - val_accuracy: 0.4386\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.4079 - accuracy: 0.4531 - val_loss: 2.4660 - val_accuracy: 0.4400\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.4025 - accuracy: 0.4503 - val_loss: 2.4182 - val_accuracy: 0.4490\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.3845 - accuracy: 0.4573 - val_loss: 2.4270 - val_accuracy: 0.4500\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.3789 - accuracy: 0.4599 - val_loss: 2.4369 - val_accuracy: 0.4442\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3628 - accuracy: 0.4598 - val_loss: 2.4232 - val_accuracy: 0.4471\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.3500 - accuracy: 0.4645 - val_loss: 2.3943 - val_accuracy: 0.4534\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.3398 - accuracy: 0.4667 - val_loss: 2.3703 - val_accuracy: 0.4579\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3240 - accuracy: 0.4723 - val_loss: 2.3588 - val_accuracy: 0.4615\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.3198 - accuracy: 0.4722 - val_loss: 2.3547 - val_accuracy: 0.4636\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.3153 - accuracy: 0.4709 - val_loss: 2.3675 - val_accuracy: 0.4600\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2992 - accuracy: 0.4766 - val_loss: 2.3552 - val_accuracy: 0.4646\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.2866 - accuracy: 0.4789 - val_loss: 2.3528 - val_accuracy: 0.4623\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2822 - accuracy: 0.4798 - val_loss: 2.3426 - val_accuracy: 0.4641\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.2755 - accuracy: 0.4814 - val_loss: 2.3655 - val_accuracy: 0.4597\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2594 - accuracy: 0.4846 - val_loss: 2.3426 - val_accuracy: 0.4655\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2547 - accuracy: 0.4856 - val_loss: 2.3611 - val_accuracy: 0.4606\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2449 - accuracy: 0.4872 - val_loss: 2.3218 - val_accuracy: 0.4710\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.2306 - accuracy: 0.4891 - val_loss: 2.2992 - val_accuracy: 0.4737\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.2276 - accuracy: 0.4895 - val_loss: 2.3082 - val_accuracy: 0.4686\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.2176 - accuracy: 0.4938 - val_loss: 2.3139 - val_accuracy: 0.4697\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.2089 - accuracy: 0.4922 - val_loss: 2.3177 - val_accuracy: 0.4626\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.2005 - accuracy: 0.4960 - val_loss: 2.3165 - val_accuracy: 0.4678\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1960 - accuracy: 0.4978 - val_loss: 2.3138 - val_accuracy: 0.4709\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1805 - accuracy: 0.5004 - val_loss: 2.2891 - val_accuracy: 0.4766\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1813 - accuracy: 0.5028 - val_loss: 2.2744 - val_accuracy: 0.4811\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.1699 - accuracy: 0.5042 - val_loss: 2.2821 - val_accuracy: 0.4786\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.1661 - accuracy: 0.5064 - val_loss: 2.2845 - val_accuracy: 0.4758\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1539 - accuracy: 0.5085 - val_loss: 2.2724 - val_accuracy: 0.4770\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.1435 - accuracy: 0.5114 - val_loss: 2.2712 - val_accuracy: 0.4804\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1470 - accuracy: 0.5086 - val_loss: 2.2521 - val_accuracy: 0.4843\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1290 - accuracy: 0.5133 - val_loss: 2.2755 - val_accuracy: 0.4786\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.1237 - accuracy: 0.5136 - val_loss: 2.2645 - val_accuracy: 0.4839\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1168 - accuracy: 0.5161 - val_loss: 2.2409 - val_accuracy: 0.4890\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.1064 - accuracy: 0.5202 - val_loss: 2.2440 - val_accuracy: 0.4857\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 2.1081 - accuracy: 0.5203 - val_loss: 2.2582 - val_accuracy: 0.4864\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 2.0949 - accuracy: 0.5195 - val_loss: 2.2500 - val_accuracy: 0.4836\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 2.0973 - accuracy: 0.5244 - val_loss: 2.2461 - val_accuracy: 0.4840\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0870 - accuracy: 0.5224 - val_loss: 2.2374 - val_accuracy: 0.4862\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0817 - accuracy: 0.5263 - val_loss: 2.2571 - val_accuracy: 0.4862\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0749 - accuracy: 0.5273 - val_loss: 2.2269 - val_accuracy: 0.4932\n",
            "Epoch 77/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0705 - accuracy: 0.5277 - val_loss: 2.2376 - val_accuracy: 0.4926\n",
            "Epoch 78/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0584 - accuracy: 0.5295 - val_loss: 2.2178 - val_accuracy: 0.4929\n",
            "Epoch 79/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.0560 - accuracy: 0.5313 - val_loss: 2.2119 - val_accuracy: 0.4939\n",
            "Epoch 80/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0491 - accuracy: 0.5330 - val_loss: 2.2286 - val_accuracy: 0.4935\n",
            "Epoch 81/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.0407 - accuracy: 0.5358 - val_loss: 2.2258 - val_accuracy: 0.4922\n",
            "Epoch 82/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.0352 - accuracy: 0.5358 - val_loss: 2.2368 - val_accuracy: 0.4882\n",
            "Epoch 83/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 2.0302 - accuracy: 0.5387 - val_loss: 2.2207 - val_accuracy: 0.4933\n",
            "Epoch 84/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.0224 - accuracy: 0.5385 - val_loss: 2.2058 - val_accuracy: 0.4961\n",
            "Epoch 85/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.0218 - accuracy: 0.5369 - val_loss: 2.2230 - val_accuracy: 0.4910\n",
            "Epoch 86/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.0113 - accuracy: 0.5458 - val_loss: 2.2168 - val_accuracy: 0.4974\n",
            "Epoch 87/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.0113 - accuracy: 0.5426 - val_loss: 2.2222 - val_accuracy: 0.4904\n",
            "Epoch 88/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 2.0076 - accuracy: 0.5458 - val_loss: 2.1997 - val_accuracy: 0.4989\n",
            "Epoch 89/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.9995 - accuracy: 0.5464 - val_loss: 2.2010 - val_accuracy: 0.5008\n",
            "Epoch 90/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 1.9927 - accuracy: 0.5481 - val_loss: 2.1978 - val_accuracy: 0.4950\n",
            "Epoch 91/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 1.9865 - accuracy: 0.5498 - val_loss: 2.1790 - val_accuracy: 0.5085\n",
            "Epoch 92/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.9818 - accuracy: 0.5490 - val_loss: 2.2074 - val_accuracy: 0.4990\n",
            "Epoch 93/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.9781 - accuracy: 0.5506 - val_loss: 2.1795 - val_accuracy: 0.5006\n",
            "Epoch 94/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 1.9761 - accuracy: 0.5523 - val_loss: 2.1952 - val_accuracy: 0.5022\n",
            "Epoch 95/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.9669 - accuracy: 0.5545 - val_loss: 2.1741 - val_accuracy: 0.5074\n",
            "Epoch 96/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.9622 - accuracy: 0.5565 - val_loss: 2.1820 - val_accuracy: 0.5039\n",
            "Epoch 97/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.9628 - accuracy: 0.5566 - val_loss: 2.1724 - val_accuracy: 0.5066\n",
            "Epoch 98/100\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.9488 - accuracy: 0.5605 - val_loss: 2.1834 - val_accuracy: 0.5047\n",
            "Epoch 99/100\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 1.9426 - accuracy: 0.5614 - val_loss: 2.1799 - val_accuracy: 0.5065\n",
            "Epoch 100/100\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 1.9472 - accuracy: 0.5598 - val_loss: 2.1904 - val_accuracy: 0.4981\n",
            "cifar100_down_True_BTrue_LR0.0001.keras\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.1599 - accuracy: 0.5060\n",
            "Test Accuracy: 50.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show files\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-S648Mc_KBx",
        "outputId": "949b0bef-ec21-49fb-f715-b7c87ca36ad1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar100_down_False_BTrue_LR0.0001.keras  cifar100_up_True_BTrue_LR0.0001.keras  __pycache__\n",
            "cifar100_down_True_BTrue_LR0.0001.keras   main.py\t\t\t\t sample_data\n",
            "cifar100_up_False_BTrue_LR0.0001.keras\t  model.py\t\t\t\t util.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the downloading in files is bugged for colab\n",
        "# so this command is separate from saving\n",
        "\n",
        "#files.download(\"cifar100_down_False_BFalse_LR0.001.keras\")\n",
        "#files.download(\"cifar100_down_True_BFalse_LR0.001.keras\")\n",
        "#files.download(\"cifar100_up_False_BFalse_LR0.001.keras\")\n",
        "#files.download(\"cifar100_up_True_BFalse_LR0.001.keras\")\n",
        "\n",
        "#files.download(\"cifar100_down_False_BTrue_LR0.001.keras\")\n",
        "#files.download(\"cifar100_down_True_BTrue_LR0.001.keras\")\n",
        "#files.download(\"cifar100_up_False_BTrue_LR0.001.keras\")\n",
        "#files.download(\"cifar100_up_True_BTrue_LR0.001.keras\")\n",
        "\n",
        "#files.download(\"cifar100_down_False_BFalse_LR0.0001.keras\")\n",
        "#files.download(\"cifar100_down_True_BFalse_LR0.0001.keras\")\n",
        "#files.download(\"cifar100_up_False_BFalse_LR0.0001.keras\")\n",
        "#files.download(\"cifar100_up_True_BFalse_LR0.0001.keras\")\n",
        "\n",
        "files.download(\"cifar100_down_False_BTrue_LR0.0001.keras\")\n",
        "files.download(\"cifar100_down_True_BTrue_LR0.0001.keras\")\n",
        "files.download(\"cifar100_up_False_BTrue_LR0.0001.keras\")\n",
        "files.download(\"cifar100_up_True_BTrue_LR0.0001.keras\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YGJmaujFALW9",
        "outputId": "4922be78-a7ee-4d39-c495-60337347b0d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_92047139-4d5a-473d-8eb4-a4f79cb129da\", \"cifar100_down_False_BTrue_LR0.0001.keras\", 3367037)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0d35318b-d7bb-4094-beb4-90e09cfa0cf6\", \"cifar100_down_True_BTrue_LR0.0001.keras\", 4467824)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_978270ec-1fdc-46b5-8904-eb2be6c87c7b\", \"cifar100_up_False_BTrue_LR0.0001.keras\", 8054508)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af00bc7f-2d22-45bf-8b7f-f12f939ba6a5\", \"cifar100_up_True_BTrue_LR0.0001.keras\", 10717795)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}