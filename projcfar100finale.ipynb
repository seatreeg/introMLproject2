{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile util.py\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "def exportModel(history, polarity, amsgrad, model):\n",
        "  \"\"\"\n",
        "  this function allows us to save the model in its final state\n",
        "  for later experimentation, use, and reproducability storage\n",
        "\n",
        "  NOTE: this function is designed for google colab\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  fileName=\"cifar100_\"+str(polarity)+\"_\"+str(amsgrad)+\".keras\"\n",
        "  print(fileName)\n",
        "  model.save(fileName)\n",
        "  #files.download(fileName)\n",
        "\n",
        "\n",
        "def getData(reproSeed=1):\n",
        "  \"\"\"\n",
        "  this function not only grabs the data from the source\n",
        "  but also does a true 3 way split\n",
        "  as a 2 way split is only performed by default\n",
        "  which does not provide validation data\n",
        "\n",
        "  this function also prepares the data in a way\n",
        "  that works well with our model setup\n",
        "  \"\"\"\n",
        "\n",
        "  # first split, from obtaining the data\n",
        "  (trainValImgs, trainValLabels),(testImgs, testLabels)= datasets.cifar100.load_data( )\n",
        "\n",
        "  # normalize the values because 255 format\n",
        "  # makes things difficult\n",
        "  trainValImgs = trainValImgs/255\n",
        "  testImgs = testImgs/255\n",
        "\n",
        "  #flatten to ensure compatable with later functions\n",
        "  trainValLabels = trainValLabels.ravel()\n",
        "  testLabels = testLabels.ravel()\n",
        "\n",
        "\n",
        "  # second split is needed to run testing\n",
        "  trainImgs, valImgs, trainLabels, valLabels = train_test_split(trainValImgs,\n",
        "                                                              trainValLabels,\n",
        "                                                              test_size=0.25,\n",
        "                                                              random_state=reproSeed)\n",
        "\n",
        "  return trainImgs, valImgs, trainLabels, valLabels, testImgs, testLabels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUFKHQIVvcP1",
        "outputId": "231d4c43-4fd1-426e-e5de-9445d9302726"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting util.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqvD5CYRt_jY",
        "outputId": "f4feab49-6deb-4313-8520-47d7d18a4e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "def modelMaker(amsgrad= False, polarity = \"up\"):\n",
        "  \"\"\"\n",
        "  this function creates and compiles a model\n",
        "\n",
        "  there are two settings for the architecture:\n",
        "    'up'   : the convolutional layers build up in filter count\n",
        "    'down' : the convolutional layers build down on filter count\n",
        "    (all kernels are the same size)\n",
        "\n",
        "  there are two settings for hyperparamters\n",
        "    'True' : ams grad is on\n",
        "    'False': ams grad is off\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  match polarity:\n",
        "    case \"up\":\n",
        "      model = models.Sequential([\n",
        "        layers.Input(shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        #layers.Conv2D(32, 3, strides=2, padding='same', use_bias=False),\n",
        "\n",
        "        layers.Conv2D(32, 3, padding='same', use_bias=False), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(64, 3, padding='same', use_bias=False), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(128, 3, padding='same', use_bias=False), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "        layers.Flatten(),\n",
        "\n",
        "\n",
        "        layers.Dense(256, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(128, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(100, activation=\"softmax\")\n",
        "      ])\n",
        "      adamm=Adam(amsgrad=amsgrad)\n",
        "      model.compile(optimizer=adamm,\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "      return model\n",
        "\n",
        "\n",
        "    case \"down\":\n",
        "      model = models.Sequential([\n",
        "        layers.Input(shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        #layers.Conv2D(32, 3, strides=2, padding='same', use_bias=False),\n",
        "\n",
        "        layers.Conv2D(128, 3, padding='same', use_bias=False), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(64, 3, padding='same', use_bias=False), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(32, 3, padding='same', use_bias=False), #128\n",
        "        layers.Activation('swish'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "        layers.Flatten(),\n",
        "\n",
        "\n",
        "        layers.Dense(256, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(128, activation=\"silu\", kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(100, activation=\"softmax\")\n",
        "      ])\n",
        "      adamm=Adam(amsgrad=amsgrad)\n",
        "      model.compile(optimizer=adamm,\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "      return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "\n",
        "from util import *\n",
        "from model import *\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mainrun(polarity, amsgrad):\n",
        "  \"\"\"\n",
        "  this function is the main run for setting up\n",
        "  fitting, testing, and exporting our model\n",
        "\n",
        "  there are some manipulatable settings\n",
        "  but nothing that should be changed between tests\n",
        "  \"\"\"\n",
        "  # seed for reproducability\n",
        "  reproSeed=1\n",
        "  # max epochs\n",
        "  epoccs=20#00\n",
        "  # early stopping, does not always activate\n",
        "  # due to other regularizers at play\n",
        "  callback = callbacks.EarlyStopping(monitor='loss',\n",
        "                                                patience=5,\n",
        "                                                restore_best_weights=True)\n",
        "\n",
        "  # get cifar100 fine data with full 3 way split\n",
        "  trainImgs, valImgs, trainLabels, valLabels, testImgs, testLabels = getData(reproSeed=reproSeed)\n",
        "\n",
        "  # generate the model with architecture based on up or down\n",
        "  # and amsgrad on or off\n",
        "  model = modelMaker(amsgrad=amsgrad , polarity=polarity)\n",
        "\n",
        "  # show relavant information about the model\n",
        "  print(\"polarity:\", polarity,\"   amsgrad:\",  amsgrad)\n",
        "  model.summary()\n",
        "\n",
        "  # fit the model\n",
        "  history = model.fit(\n",
        "    trainImgs, trainLabels, epochs=epoccs, validation_data=(valImgs, valLabels),\n",
        "    callbacks=[callback], batch_size=50\n",
        "  )\n",
        "\n",
        "  # download the model so you can use it later\n",
        "  exportModel(history=history, polarity=polarity, amsgrad=amsgrad, model=model)\n",
        "\n",
        "  # placeholder until we get resampled CI testacc\n",
        "  testLoss, testAcc = model.evaluate(testImgs, testLabels)\n",
        "  print(f\"Test Accuracy: {testAcc*100:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  \"\"\"\n",
        "  each of these function calls is a new test\n",
        "  we need four total\n",
        "  (two architectures two hyperparameters)\n",
        "  more can be added, and individual ones can\n",
        "  be commed out\n",
        "  since these models take a long time to train\n",
        "\n",
        "  This setup helps maintain that we change\n",
        "  what we are interested in for the experiment\n",
        "  and hold all else constant\n",
        "  \"\"\"\n",
        "\n",
        "  mainrun(polarity=\"up\", amsgrad=False)\n",
        "  mainrun(polarity=\"up\", amsgrad=True)\n",
        "  mainrun(polarity=\"down\", amsgrad=False)\n",
        "  mainrun(polarity=\"down\", amsgrad=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UfILMXtvDsc",
        "outputId": "fc66a8be-c33f-4a3e-86fd-89b6fd77db82"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPcJDqOq2ILS",
        "outputId": "92a23552-2f9a-4c8c-d798-9dff31a43253"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-08 06:24:23.450356: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:95] Opening library: /usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2\n",
            "2024-07-08 06:24:23.450538: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:119] Libtpu path is: libtpu.so\n",
            "2024-07-08 06:24:23.504273: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-08 06:24:34.870728: I external/local_xla/xla/service/service.cc:168] XLA service 0x592cb8ba2d60 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\n",
            "2024-07-08 06:24:34.870783: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): TPU, 2a886c8\n",
            "2024-07-08 06:24:34.870793: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): TPU, 2a886c8\n",
            "2024-07-08 06:24:34.870800: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (2): TPU, 2a886c8\n",
            "2024-07-08 06:24:34.870812: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (3): TPU, 2a886c8\n",
            "2024-07-08 06:24:34.870828: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (4): TPU, 2a886c8\n",
            "2024-07-08 06:24:34.870839: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (5): TPU, 2a886c8\n",
            "2024-07-08 06:24:34.870852: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (6): TPU, 2a886c8\n",
            "2024-07-08 06:24:34.870866: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (7): TPU, 2a886c8\n",
            "2024-07-08 06:24:34.871033: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.871114: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.871232: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.871312: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.871407: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.871606: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.871723: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.871815: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.871932: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.872027: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.872233: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.872336: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.872441: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.872524: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.872656: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.872846: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.872948: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.873025: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.873106: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.873271: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.873460: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.873563: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.873642: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.873758: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.873853: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.874055: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.874169: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.874275: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.874373: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.874469: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.874716: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.874798: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.874893: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.875019: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.875124: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.875386: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.875483: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.875574: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.875684: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "2024-07-08 06:24:34.875808: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
            "polarity: up    amsgrad: False\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (Batch  (None, 32, 32, 3)         12        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        864       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18432     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73728     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664272 (2.53 MB)\n",
            "Trainable params: 663818 (2.53 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "750/750 [==============================] - 27s 34ms/step - loss: 4.9093 - accuracy: 0.1407 - val_loss: 3.6838 - val_accuracy: 0.2054\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 3.4804 - accuracy: 0.2479 - val_loss: 3.4506 - val_accuracy: 0.2635\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 3.2287 - accuracy: 0.3017 - val_loss: 3.0829 - val_accuracy: 0.3333\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 3.0821 - accuracy: 0.3387 - val_loss: 3.0461 - val_accuracy: 0.3444\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.9884 - accuracy: 0.3599 - val_loss: 2.9629 - val_accuracy: 0.3682\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.9206 - accuracy: 0.3785 - val_loss: 2.9834 - val_accuracy: 0.3757\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.8563 - accuracy: 0.3946 - val_loss: 2.8705 - val_accuracy: 0.4034\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.8106 - accuracy: 0.4073 - val_loss: 2.8212 - val_accuracy: 0.4120\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.7733 - accuracy: 0.4162 - val_loss: 2.8169 - val_accuracy: 0.4093\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.7354 - accuracy: 0.4243 - val_loss: 2.8723 - val_accuracy: 0.4029\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.7135 - accuracy: 0.4320 - val_loss: 2.7800 - val_accuracy: 0.4226\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.6847 - accuracy: 0.4382 - val_loss: 2.7978 - val_accuracy: 0.4198\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.6585 - accuracy: 0.4423 - val_loss: 2.7546 - val_accuracy: 0.4267\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.6453 - accuracy: 0.4475 - val_loss: 2.7134 - val_accuracy: 0.4338\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.6163 - accuracy: 0.4510 - val_loss: 2.6880 - val_accuracy: 0.4438\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.6021 - accuracy: 0.4545 - val_loss: 2.7462 - val_accuracy: 0.4294\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.6100 - accuracy: 0.4558 - val_loss: 2.7520 - val_accuracy: 0.4321\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.5710 - accuracy: 0.4635 - val_loss: 2.6805 - val_accuracy: 0.4467\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.5842 - accuracy: 0.4639 - val_loss: 2.6945 - val_accuracy: 0.4438\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.5444 - accuracy: 0.4699 - val_loss: 2.6839 - val_accuracy: 0.4410\n",
            "cifar100_up_False.keras\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.6591 - accuracy: 0.4482\n",
            "Test Accuracy: 44.82%\n",
            "polarity: up    amsgrad: True\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_4 (Bat  (None, 32, 32, 3)         12        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 32)        864       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 16, 64)        18432     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         73728     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664272 (2.53 MB)\n",
            "Trainable params: 663818 (2.53 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "750/750 [==============================] - 27s 34ms/step - loss: 4.9199 - accuracy: 0.1462 - val_loss: 3.7129 - val_accuracy: 0.2054\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 3.4495 - accuracy: 0.2546 - val_loss: 3.3424 - val_accuracy: 0.2722\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 3.1986 - accuracy: 0.3078 - val_loss: 3.0819 - val_accuracy: 0.3272\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 3.0470 - accuracy: 0.3404 - val_loss: 3.0732 - val_accuracy: 0.3382\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.9510 - accuracy: 0.3610 - val_loss: 3.0850 - val_accuracy: 0.3381\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.8762 - accuracy: 0.3772 - val_loss: 2.9328 - val_accuracy: 0.3726\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.8219 - accuracy: 0.3951 - val_loss: 2.8419 - val_accuracy: 0.3894\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.7723 - accuracy: 0.4030 - val_loss: 2.8081 - val_accuracy: 0.3990\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.7232 - accuracy: 0.4154 - val_loss: 2.7910 - val_accuracy: 0.4059\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.6876 - accuracy: 0.4234 - val_loss: 2.8183 - val_accuracy: 0.4042\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.6582 - accuracy: 0.4316 - val_loss: 2.7844 - val_accuracy: 0.4087\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.6246 - accuracy: 0.4403 - val_loss: 2.7074 - val_accuracy: 0.4283\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.6061 - accuracy: 0.4463 - val_loss: 2.7351 - val_accuracy: 0.4198\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.5884 - accuracy: 0.4477 - val_loss: 2.6778 - val_accuracy: 0.4352\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.5699 - accuracy: 0.4534 - val_loss: 2.6856 - val_accuracy: 0.4342\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.5413 - accuracy: 0.4589 - val_loss: 2.6298 - val_accuracy: 0.4453\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 2.5360 - accuracy: 0.4622 - val_loss: 2.6770 - val_accuracy: 0.4370\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.5081 - accuracy: 0.4654 - val_loss: 2.6390 - val_accuracy: 0.4409\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.4977 - accuracy: 0.4703 - val_loss: 2.6587 - val_accuracy: 0.4384\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 2.4867 - accuracy: 0.4743 - val_loss: 2.5980 - val_accuracy: 0.4506\n",
            "cifar100_up_True.keras\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 2.5539 - accuracy: 0.4657\n",
            "Test Accuracy: 46.57%\n",
            "polarity: down    amsgrad: False\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_8 (Bat  (None, 32, 32, 3)         12        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 128)       3456      \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 32, 32, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 16, 16, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 64)        73728     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 8, 8, 32)          18432     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 8, 8, 32)          128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 4, 4, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 4, 4, 32)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273648 (1.04 MB)\n",
            "Trainable params: 273194 (1.04 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "750/750 [==============================] - 42s 54ms/step - loss: 4.8330 - accuracy: 0.1304 - val_loss: 3.6493 - val_accuracy: 0.1845\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 39s 51ms/step - loss: 3.4831 - accuracy: 0.2219 - val_loss: 3.2260 - val_accuracy: 0.2688\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 3.2268 - accuracy: 0.2690 - val_loss: 3.1232 - val_accuracy: 0.2924\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 3.0690 - accuracy: 0.3021 - val_loss: 3.0275 - val_accuracy: 0.3189\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.9576 - accuracy: 0.3281 - val_loss: 2.8730 - val_accuracy: 0.3393\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.8672 - accuracy: 0.3469 - val_loss: 2.8072 - val_accuracy: 0.3631\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.8074 - accuracy: 0.3596 - val_loss: 2.7264 - val_accuracy: 0.3769\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 38s 50ms/step - loss: 2.7496 - accuracy: 0.3715 - val_loss: 2.6908 - val_accuracy: 0.3871\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.7127 - accuracy: 0.3836 - val_loss: 2.6876 - val_accuracy: 0.3888\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.6725 - accuracy: 0.3868 - val_loss: 2.6144 - val_accuracy: 0.4013\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.6351 - accuracy: 0.3958 - val_loss: 2.6017 - val_accuracy: 0.4076\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.6109 - accuracy: 0.4027 - val_loss: 2.6120 - val_accuracy: 0.4025\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.5765 - accuracy: 0.4070 - val_loss: 2.5894 - val_accuracy: 0.4068\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 38s 50ms/step - loss: 2.5595 - accuracy: 0.4127 - val_loss: 2.5782 - val_accuracy: 0.4163\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.5307 - accuracy: 0.4187 - val_loss: 2.5498 - val_accuracy: 0.4194\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.5104 - accuracy: 0.4214 - val_loss: 2.5180 - val_accuracy: 0.4175\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - 38s 50ms/step - loss: 2.4978 - accuracy: 0.4283 - val_loss: 2.5660 - val_accuracy: 0.4107\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - 38s 50ms/step - loss: 2.4849 - accuracy: 0.4297 - val_loss: 2.4940 - val_accuracy: 0.4374\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.4633 - accuracy: 0.4337 - val_loss: 2.4634 - val_accuracy: 0.4344\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.4628 - accuracy: 0.4346 - val_loss: 2.4754 - val_accuracy: 0.4375\n",
            "cifar100_down_False.keras\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.4705 - accuracy: 0.4418\n",
            "Test Accuracy: 44.18%\n",
            "polarity: down    amsgrad: True\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_12 (Ba  (None, 32, 32, 3)         12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 128)       3456      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 32, 32, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 16, 16, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 64)        73728     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 8, 8, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 32)          18432     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 8, 8, 32)          128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 4, 4, 32)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 4, 4, 32)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273648 (1.04 MB)\n",
            "Trainable params: 273194 (1.04 MB)\n",
            "Non-trainable params: 454 (1.77 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "750/750 [==============================] - 42s 53ms/step - loss: 4.8051 - accuracy: 0.1315 - val_loss: 3.6203 - val_accuracy: 0.1951\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 3.4786 - accuracy: 0.2205 - val_loss: 3.3081 - val_accuracy: 0.2550\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 3.2100 - accuracy: 0.2743 - val_loss: 3.0609 - val_accuracy: 0.3134\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 3.0421 - accuracy: 0.3113 - val_loss: 2.9252 - val_accuracy: 0.3359\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.9260 - accuracy: 0.3342 - val_loss: 2.8208 - val_accuracy: 0.3571\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.8517 - accuracy: 0.3458 - val_loss: 2.7467 - val_accuracy: 0.3743\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.7840 - accuracy: 0.3632 - val_loss: 2.7292 - val_accuracy: 0.3749\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 39s 52ms/step - loss: 2.7358 - accuracy: 0.3715 - val_loss: 2.6523 - val_accuracy: 0.3918\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 38s 50ms/step - loss: 2.6891 - accuracy: 0.3819 - val_loss: 2.6094 - val_accuracy: 0.4034\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.6514 - accuracy: 0.3883 - val_loss: 2.6171 - val_accuracy: 0.3963\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.6150 - accuracy: 0.3983 - val_loss: 2.5529 - val_accuracy: 0.4162\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.5963 - accuracy: 0.4033 - val_loss: 2.5847 - val_accuracy: 0.4086\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.5633 - accuracy: 0.4079 - val_loss: 2.5992 - val_accuracy: 0.4034\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.5390 - accuracy: 0.4129 - val_loss: 2.5508 - val_accuracy: 0.4121\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 38s 50ms/step - loss: 2.5230 - accuracy: 0.4171 - val_loss: 2.5118 - val_accuracy: 0.4228\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 38s 50ms/step - loss: 2.5008 - accuracy: 0.4200 - val_loss: 2.5419 - val_accuracy: 0.4185\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - 38s 50ms/step - loss: 2.4924 - accuracy: 0.4234 - val_loss: 2.4832 - val_accuracy: 0.4350\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - 38s 50ms/step - loss: 2.4655 - accuracy: 0.4304 - val_loss: 2.4671 - val_accuracy: 0.4318\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - 37s 50ms/step - loss: 2.4549 - accuracy: 0.4313 - val_loss: 2.4834 - val_accuracy: 0.4295\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.4383 - accuracy: 0.4355 - val_loss: 2.4711 - val_accuracy: 0.4288\n",
            "cifar100_down_True.keras\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.4447 - accuracy: 0.4387\n",
            "Test Accuracy: 43.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show files\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-S648Mc_KBx",
        "outputId": "8fafb745-1bb7-495b-f021-6656c55bc209"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar100_down_False.keras  cifar100_up_False.keras  main.py   __pycache__  util.py\n",
            "cifar100_down_True.keras   cifar100_up_True.keras   model.py  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the downloading in files is bugged for colab\n",
        "# so this command is separate from saving\n",
        "\n",
        "files.download(\"cifar100_down_False.keras\")\n",
        "files.download(\"cifar100_down_True.keras\")\n",
        "files.download(\"cifar100_up_False.keras\")\n",
        "files.download(\"cifar100_up_True.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YGJmaujFALW9",
        "outputId": "49aad22e-2c4c-42b1-9807-68bd28bb3109"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e365514c-9537-4f8c-9bf4-9a00c1560fa1\", \"cifar100_down_False.keras\", 3361248)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3f14ccaa-8b5c-47fa-8e7d-49d34081ed87\", \"cifar100_down_True.keras\", 4460323)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f932a4f4-ad6f-4408-b7da-0a376dd3cf69\", \"cifar100_up_False.keras\", 8048719)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1d552abf-d439-47cd-b31d-241247545b92\", \"cifar100_up_True.keras\", 10710294)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}